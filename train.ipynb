{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b92c8101",
      "metadata": {
        "papermill": {
          "duration": 0.004733,
          "end_time": "2025-11-29T10:09:33.002281",
          "exception": false,
          "start_time": "2025-11-29T10:09:32.997548",
          "status": "completed"
        },
        "tags": [],
        "id": "b92c8101"
      },
      "source": [
        "# Imports and configs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Googleドライブをマウント\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. 作業用フォルダの作成と移動\n",
        "\n",
        "WORKING_DIR = \"/content/drive/MyDrive/Kaggle/MABe\"\n",
        "\n",
        "# カレントディレクトリ変更\n",
        "os.chdir(WORKING_DIR)\n",
        "print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "ICbFrcIQwGgq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ICbFrcIQwGgq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 1.836241,
          "end_time": "2025-11-29T10:09:34.843101",
          "exception": false,
          "start_time": "2025-11-29T10:09:33.006860",
          "status": "completed"
        },
        "tags": [],
        "id": "0fa7e39d"
      },
      "outputs": [],
      "source": [
        "# @title スコア評価用関数\n",
        "\"\"\"F Beta customized for the data format of the MABe challenge.\"\"\"\n",
        "\n",
        "import json\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "\n",
        "class HostVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
        "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
        "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
        "\n",
        "    for row in lab_solution.to_dicts():\n",
        "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
        "\n",
        "    for video in lab_solution['video_id'].unique():\n",
        "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
        "        active_labels: set[str] = set(json.loads(active_labels))\n",
        "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
        "\n",
        "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
        "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
        "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
        "                continue\n",
        "\n",
        "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
        "            # Ignore truly redundant predictions.\n",
        "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
        "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
        "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
        "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
        "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
        "            prediction_frames[row['prediction_key']].update(new_frames)\n",
        "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
        "\n",
        "    tps = defaultdict(int)\n",
        "    fns = defaultdict(int)\n",
        "    fps = defaultdict(int)\n",
        "    for key, pred_frames in prediction_frames.items():\n",
        "        action = key.split('_')[-1]\n",
        "        matched_label_frames = label_frames[key]\n",
        "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
        "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
        "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
        "\n",
        "    distinct_actions = set()\n",
        "    for key, frames in label_frames.items():\n",
        "        action = key.split('_')[-1]\n",
        "        distinct_actions.add(action)\n",
        "        if key not in prediction_frames:\n",
        "            fns[action] += len(frames)\n",
        "\n",
        "    action_f1s = []\n",
        "    for action in distinct_actions:\n",
        "        if tps[action] + fns[action] + fps[action] == 0:\n",
        "            action_f1s.append(0)\n",
        "        else:\n",
        "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
        "    return sum(action_f1s) / len(action_f1s)\n",
        "\n",
        "\n",
        "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
        "    \"\"\"\n",
        "    Doctests:\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10},\n",
        "    ... ])\n",
        "    >>> mouse_fbeta(solution, submission)\n",
        "    1.0\n",
        "\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 0, 'stop_frame': 10}, # Wrong action\n",
        "    ... ])\n",
        "    >>> mouse_fbeta(solution, submission)\n",
        "    0.0\n",
        "\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
        "    ... ])\n",
        "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
        "    '0.500000000000'\n",
        "\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
        "    ... ])\n",
        "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
        "    '0.250000000000'\n",
        "\n",
        "    >>> # Overlapping solution events, one prediction matching both.\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 10, 'stop_frame': 20, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 20},\n",
        "    ... ])\n",
        "    >>> mouse_fbeta(solution, submission)\n",
        "    1.0\n",
        "\n",
        "    >>> solution = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 30, 'stop_frame': 40, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
        "    ... ])\n",
        "    >>> submission = pd.DataFrame([\n",
        "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 40},\n",
        "    ... ])\n",
        "    >>> mouse_fbeta(solution, submission)\n",
        "    0.6666666666666666\n",
        "    \"\"\"\n",
        "    if len(solution) == 0 or len(submission) == 0:\n",
        "        raise ValueError('Missing solution or submission data')\n",
        "\n",
        "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
        "\n",
        "    for col in expected_cols:\n",
        "        if col not in solution.columns:\n",
        "            raise ValueError(f'Solution is missing column {col}')\n",
        "        if col not in submission.columns:\n",
        "            raise ValueError(f'Submission is missing column {col}')\n",
        "\n",
        "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
        "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
        "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
        "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
        "    solution_videos = set(solution['video_id'].unique())\n",
        "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
        "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
        "\n",
        "    solution = solution.with_columns(\n",
        "        pl.concat_str(\n",
        "            [\n",
        "                pl.col('video_id').cast(pl.Utf8),\n",
        "                pl.col('agent_id').cast(pl.Utf8),\n",
        "                pl.col('target_id').cast(pl.Utf8),\n",
        "                pl.col('action'),\n",
        "            ],\n",
        "            separator='_',\n",
        "        ).alias('label_key'),\n",
        "    )\n",
        "    submission = submission.with_columns(\n",
        "        pl.concat_str(\n",
        "            [\n",
        "                pl.col('video_id').cast(pl.Utf8),\n",
        "                pl.col('agent_id').cast(pl.Utf8),\n",
        "                pl.col('target_id').cast(pl.Utf8),\n",
        "                pl.col('action'),\n",
        "            ],\n",
        "            separator='_',\n",
        "        ).alias('prediction_key'),\n",
        "    )\n",
        "\n",
        "    lab_scores = []\n",
        "    for lab in solution['lab_id'].unique():\n",
        "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
        "        lab_videos = set(lab_solution['video_id'].unique())\n",
        "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
        "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
        "\n",
        "    return sum(lab_scores) / len(lab_scores)\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
        "    \"\"\"\n",
        "    F1 score for the MABe Challenge\n",
        "    \"\"\"\n",
        "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
        "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
        "    return mouse_fbeta(solution, submission, beta=beta)"
      ],
      "id": "0fa7e39d"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "55vFtBUPvKAm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "55vFtBUPvKAm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": 1.574563,
          "end_time": "2025-11-29T10:09:36.422732",
          "exception": false,
          "start_time": "2025-11-29T10:09:34.848169",
          "status": "completed"
        },
        "tags": [],
        "id": "9MQ1cbwku_CX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "import numpy as np\n",
        "import itertools\n",
        "import warnings\n",
        "import optuna\n",
        "import joblib\n",
        "import glob\n",
        "import gc\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "9MQ1cbwku_CX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive上のzipファイルの場所\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/Kaggle/MABe/MABe-mouse-behavior-detection.zip\"\n",
        "LOCAL_DIR = \"/content/input_data\"\n",
        "print(\"--- Copying & Unzipping Data to Local Disk ---\")\n",
        "\n",
        "# 1. フォルダ作成\n",
        "if not os.path.exists(LOCAL_DIR):\n",
        "    os.makedirs(LOCAL_DIR)\n",
        "\n",
        "# 2. コピー & 解凍\n",
        "if not os.path.exists(f\"{LOCAL_DIR}/train.csv\"):\n",
        "    print(\"Copying zip file...\")\n",
        "    !cp \"{DRIVE_ZIP_PATH}\" /content/temp_dataset.zip\n",
        "    print(\"Unzipping...\")\n",
        "    !unzip -q /content/temp_dataset.zip -d \"{LOCAL_DIR}\"\n",
        "    !rm /content/temp_dataset.zip\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"Data already exists in local disk.\")\n"
      ],
      "metadata": {
        "id": "aWRZvn-rUlAB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aWRZvn-rUlAB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": 0.011207,
          "end_time": "2025-11-29T10:09:36.438956",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.427749",
          "status": "completed"
        },
        "tags": [],
        "id": "847647cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CFG:\n",
        "    input_dir = \"/content/input_data\"\n",
        "    !ls {input_dir}\n",
        "    train_path = f\"{input_dir}/train.csv\"\n",
        "    test_path = f\"{input_dir}/test.csv\"\n",
        "    train_annotation_path = f\"{input_dir}/train_annotation\"\n",
        "    train_tracking_path = f\"{input_dir}/train_tracking\"\n",
        "    test_tracking_path = f\"{input_dir}/test_tracking\"\n",
        "\n",
        "    model_path = \".\"      # モデル保存先\n",
        "    model_name = \"xgboost\"\n",
        "\n",
        "    mode = \"validate\"\n",
        "    #mode = \"submit\"\n",
        "\n",
        "    n_splits = 5\n",
        "    cv = StratifiedGroupKFold(n_splits)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "            verbosity=0,\n",
        "            random_state=42,\n",
        "            device='cuda',\n",
        "            tree_method='hist',\n",
        "            n_estimators=3000,\n",
        "\n",
        "            # Optuna Best Params\n",
        "            max_depth=6,\n",
        "            learning_rate=0.132,\n",
        "            min_child_weight=10,\n",
        "            subsample=0.728,\n",
        "            colsample_bytree=0.771,\n",
        "            reg_alpha=1.58,\n",
        "            reg_lambda=3.44,\n",
        "            early_stopping_rounds=50,\n",
        "        )\n",
        "\n",
        "print(f\"CFG setup complete.\")\n",
        "print(f\"Model will be saved to: {CFG.model_path}\")"
      ],
      "id": "847647cb"
    },
    {
      "cell_type": "markdown",
      "id": "804520f0",
      "metadata": {
        "papermill": {
          "duration": 0.004505,
          "end_time": "2025-11-29T10:09:36.448142",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.443637",
          "status": "completed"
        },
        "tags": [],
        "id": "804520f0"
      },
      "source": [
        "# Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "813e0c9c",
      "metadata": {
        "papermill": {
          "duration": 0.1217,
          "end_time": "2025-11-29T10:09:36.574449",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.452749",
          "status": "completed"
        },
        "tags": [],
        "id": "813e0c9c"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(CFG.train_path)\n",
        "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
        "train_without_mabe22_c_c = train[~train['lab_id'].str.startswith(('MABe22', 'CalMS21', 'CRIM13'))] #学習から除外する過去データの指定\n",
        "train = train[~train['lab_id'].str.startswith(('CalMS21', 'CRIM13'))]\n",
        "test = pd.read_csv(CFG.test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e48872b",
      "metadata": {
        "papermill": {
          "duration": 0.013634,
          "end_time": "2025-11-29T10:09:36.593032",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.579398",
          "status": "completed"
        },
        "tags": [],
        "id": "4e48872b"
      },
      "outputs": [],
      "source": [
        "body_parts_tracked_list = list(np.unique(train.body_parts_tracked)) #トラッキングされたボディパーツのセット毎のリスト作成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd720bf",
      "metadata": {
        "papermill": {
          "duration": 0.004617,
          "end_time": "2025-11-29T10:09:36.602239",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.597622",
          "status": "completed"
        },
        "tags": [],
        "id": "3cd720bf"
      },
      "source": [
        "## Creating solution data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d58baf",
      "metadata": {
        "papermill": {
          "duration": 5.945974,
          "end_time": "2025-11-29T10:09:42.552836",
          "exception": false,
          "start_time": "2025-11-29T10:09:36.606862",
          "status": "completed"
        },
        "tags": [],
        "id": "75d58baf"
      },
      "outputs": [],
      "source": [
        "def create_solution_df(dataset):\n",
        "    solution = []\n",
        "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
        "\n",
        "        lab_id = row['lab_id']\n",
        "        if lab_id.startswith(('MABe22', 'CalMS21', 'CRIM13')):\n",
        "            continue\n",
        "\n",
        "        video_id = row['video_id']\n",
        "        path = f\"{CFG.train_annotation_path}/{lab_id}/{video_id}.parquet\"\n",
        "        try:\n",
        "            annot = pd.read_parquet(path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "        annot['lab_id'] = lab_id\n",
        "        annot['video_id'] = video_id\n",
        "        annot['behaviors_labeled'] = row['behaviors_labeled']\n",
        "        annot['target_id'] = np.where(annot.target_id != annot.agent_id, annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
        "        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
        "        solution.append(annot)\n",
        "\n",
        "    solution = pd.concat(solution)\n",
        "\n",
        "    return solution\n",
        "\n",
        "if CFG.mode == 'validate':\n",
        "    solution = create_solution_df(train_without_mabe22_c_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd81b75a",
      "metadata": {
        "papermill": {
          "duration": 0.004812,
          "end_time": "2025-11-29T10:09:42.563042",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.558230",
          "status": "completed"
        },
        "tags": [],
        "id": "fd81b75a"
      },
      "source": [
        "## Data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7628ca9-4ce9-4add-ab9f-51d1d4ab20cc",
      "metadata": {
        "id": "d7628ca9-4ce9-4add-ab9f-51d1d4ab20cc"
      },
      "outputs": [],
      "source": [
        "# 1. 速度チェック (スパイク除去用)\n",
        "\n",
        "def clean_speed_outliers(df, pix_per_cm, threshold_speed_cm=10.0, smooth_sigma=1.0):\n",
        "    \"\"\"\n",
        "    前のフレームから threshold_speed_cm 以上移動している場合、異常値として除去する。\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # cm -> px 変換\n",
        "    threshold_speed_px = threshold_speed_cm * pix_per_cm\n",
        "\n",
        "    total_outliers = 0\n",
        "    total_points = 0\n",
        "\n",
        "    # 元々の欠損箇所を記録\n",
        "    original_na_mask = df_clean.isna()\n",
        "\n",
        "    try:\n",
        "        mouse_ids = df_clean.columns.get_level_values('mouse_id').unique()\n",
        "        bodyparts = df_clean.columns.get_level_values('bodypart').unique()\n",
        "    except KeyError:\n",
        "        mouse_ids = df_clean.columns.get_level_values(1).unique()\n",
        "        bodyparts = df_clean.columns.get_level_values(2).unique()\n",
        "\n",
        "    for mid in mouse_ids:\n",
        "        for bp in bodyparts:\n",
        "            col_x = ('x', mid, bp)\n",
        "            col_y = ('y', mid, bp)\n",
        "\n",
        "            if col_x not in df_clean.columns or col_y not in df_clean.columns:\n",
        "                continue\n",
        "\n",
        "            # --- 速度チェック ---\n",
        "            dx = df_clean[col_x].diff()\n",
        "            dy = df_clean[col_y].diff()\n",
        "            speed = np.sqrt(dx**2 + dy**2)\n",
        "\n",
        "            outlier_mask = speed > threshold_speed_px\n",
        "            count = outlier_mask.sum()\n",
        "\n",
        "            if count > 0:\n",
        "                total_outliers += count\n",
        "                # 異常値をNaNにする\n",
        "                df_clean.loc[outlier_mask, col_x] = np.nan\n",
        "                df_clean.loc[outlier_mask, col_y] = np.nan\n",
        "\n",
        "                # 線形補間\n",
        "                df_clean[col_x] = df_clean[col_x].interpolate(method='linear', limit_direction='both')\n",
        "                df_clean[col_y] = df_clean[col_y].interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "                # 平滑化\n",
        "                df_clean[col_x] = gaussian_filter1d(df_clean[col_x].fillna(method='bfill').fillna(method='ffill'), sigma=smooth_sigma).astype(np.float32)\n",
        "                df_clean[col_y] = gaussian_filter1d(df_clean[col_y].fillna(method='bfill').fillna(method='ffill'), sigma=smooth_sigma).astype(np.float32)\n",
        "\n",
        "            total_points += len(df_clean)\n",
        "\n",
        "    # 元々NaNだった場所をNaNに戻す\n",
        "    df_clean = df_clean.mask(original_na_mask, np.nan)\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# 2. 距離チェック\n",
        "\n",
        "def clean_distance_outliers(df, pix_per_cm, threshold_dist_cm=15.0, smooth_sigma=1.0):\n",
        "    \"\"\"\n",
        "    重心からの距離が threshold_dist_cm 以上離れている場合、異常値として除去する。\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # cm -> px 変換\n",
        "    threshold_dist_px = threshold_dist_cm * pix_per_cm\n",
        "\n",
        "    total_outliers = 0\n",
        "    total_points = 0\n",
        "\n",
        "    # 元々の欠損箇所を記録\n",
        "    original_na_mask = df_clean.isna()\n",
        "\n",
        "    try:\n",
        "        mouse_ids = df_clean.columns.get_level_values('mouse_id').unique()\n",
        "        bodyparts = df_clean.columns.get_level_values('bodypart').unique()\n",
        "    except KeyError:\n",
        "        mouse_ids = df_clean.columns.get_level_values(1).unique()\n",
        "        bodyparts = df_clean.columns.get_level_values(2).unique()\n",
        "\n",
        "    for mid in mouse_ids:\n",
        "        # 重心取得 (基準点)\n",
        "        if ('x', mid, 'body_center') in df_clean.columns:\n",
        "            center_x = df_clean[('x', mid, 'body_center')]\n",
        "            center_y = df_clean[('y', mid, 'body_center')]\n",
        "        else:\n",
        "            # 重心がなければ平均で代用\n",
        "            center_x = df_clean.xs(mid, level=1, axis=1).xs('x', level=1, axis=1).mean(axis=1)\n",
        "            center_y = df_clean.xs(mid, level=1, axis=1).xs('y', level=1, axis=1).mean(axis=1)\n",
        "\n",
        "        for bp in bodyparts:\n",
        "            # body_center 自体はチェックしない\n",
        "            if bp == 'body_center': continue\n",
        "\n",
        "            col_x = ('x', mid, bp)\n",
        "            col_y = ('y', mid, bp)\n",
        "\n",
        "            if col_x not in df_clean.columns: continue\n",
        "\n",
        "            # --- 距離チェック ---\n",
        "            dist_from_center = np.sqrt((df_clean[col_x] - center_x)**2 + (df_clean[col_y] - center_y)**2)\n",
        "            outlier_mask = dist_from_center > threshold_dist_px\n",
        "\n",
        "            count = outlier_mask.sum()\n",
        "\n",
        "            if count > 0:\n",
        "                total_outliers += count\n",
        "                # 異常値をNaNにする\n",
        "                df_clean.loc[outlier_mask, col_x] = np.nan\n",
        "                df_clean.loc[outlier_mask, col_y] = np.nan\n",
        "\n",
        "                # 線形補間\n",
        "                df_clean[col_x] = df_clean[col_x].interpolate(method='linear', limit_direction='both')\n",
        "                df_clean[col_y] = df_clean[col_y].interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "                # 平滑化\n",
        "                df_clean[col_x] = gaussian_filter1d(df_clean[col_x].fillna(method='bfill').fillna(method='ffill'), sigma=smooth_sigma).astype(np.float32)\n",
        "                df_clean[col_y] = gaussian_filter1d(df_clean[col_y].fillna(method='bfill').fillna(method='ffill'), sigma=smooth_sigma).astype(np.float32)\n",
        "\n",
        "            total_points += len(df_clean)\n",
        "\n",
        "    # 元々NaNだった場所をNaNに戻す\n",
        "    df_clean = df_clean.mask(original_na_mask, np.nan)\n",
        "\n",
        "    return df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a11ec92f-fcab-4707-8a8e-b6aac187b077",
      "metadata": {
        "papermill": {
          "duration": 0.023321,
          "end_time": "2025-11-29T10:09:42.591261",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.567940",
          "status": "completed"
        },
        "tags": [],
        "id": "a11ec92f-fcab-4707-8a8e-b6aac187b077"
      },
      "outputs": [],
      "source": [
        "drop_body_parts =  [\n",
        "    'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright',\n",
        "    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright',\n",
        "    'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
        "]\n",
        "\n",
        "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
        "    if traintest_directory is None:\n",
        "        traintest_directory = f\"CFG.input_dir/{traintest}_tracking\"\n",
        "\n",
        "    for _, row in dataset.iterrows():\n",
        "        lab_id = row.lab_id\n",
        "        if lab_id.startswith(('MABe22', 'CalMS21', 'CRIM13')) or type(row.behaviors_labeled) != str:\n",
        "            continue\n",
        "\n",
        "        video_id = row.video_id\n",
        "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
        "\n",
        "        try:\n",
        "            vid = pd.read_parquet(path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "        if len(np.unique(vid.bodypart)) > 5:\n",
        "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
        "\n",
        "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
        "        pvid = pvid.astype(np.float32)\n",
        "\n",
        "        del vid\n",
        "        gc.collect()\n",
        "\n",
        "        # 1. 速度チェック (スパイク除去)\n",
        "        if 'clean_speed_outliers' in globals():\n",
        "            pvid = clean_speed_outliers(pvid,\n",
        "                                        pix_per_cm=row.pix_per_cm_approx,\n",
        "                                        threshold_speed_cm=5.0)\n",
        "\n",
        "        # 2. Body Center 補完\n",
        "        try:\n",
        "            # pvidの構造: Columns=(x/y, mouse_id, bodypart)\n",
        "            mouse_ids = np.unique(pvid.columns.get_level_values('mouse_id'))\n",
        "\n",
        "            for mid in mouse_ids:\n",
        "                try:\n",
        "                    # マウスのデータを抽出 (Level 0: x/y, Level 1: bodypart)\n",
        "                    mouse_data = pvid.xs(mid, level='mouse_id', axis=1)\n",
        "                    available_parts = list(np.unique(mouse_data.columns.get_level_values('bodypart')))\n",
        "                    # body_center が既に存在する場合は何もしない\n",
        "                    if 'body_center' in available_parts:\n",
        "                        continue\n",
        "                    # 1. 優先度3: 低 - 全パーツの平均\n",
        "                    mean_x = mouse_data.xs('x', level=0, axis=1).mean(axis=1)\n",
        "                    mean_y = mouse_data.xs('y', level=0, axis=1).mean(axis=1)\n",
        "\n",
        "                    # final_x, final_y の初期値として平均値をセット\n",
        "                    final_x = mean_x\n",
        "                    final_y = mean_y\n",
        "\n",
        "                    # 2. 優先度2 中 - 耳と尻尾\n",
        "                    if {'ear_left', 'ear_right', 'tail_base'}.issubset(available_parts):\n",
        "                        neck_x = (mouse_data[('x', 'ear_left')] + mouse_data[('x', 'ear_right')]) / 2\n",
        "                        neck_y = (mouse_data[('y', 'ear_left')] + mouse_data[('y', 'ear_right')]) / 2\n",
        "                        tail_x = mouse_data[('x', 'tail_base')]\n",
        "                        tail_y = mouse_data[('y', 'tail_base')]\n",
        "\n",
        "                        ratio_ear = 0.541\n",
        "                        est_x_ear = neck_x + (tail_x - neck_x) * ratio_ear\n",
        "                        est_y_ear = neck_y + (tail_y - neck_y) * ratio_ear\n",
        "\n",
        "                        # 優先度2の値を上書き\n",
        "                        final_x = est_x_ear.combine_first(final_x)\n",
        "                        final_y = est_y_ear.combine_first(final_y)\n",
        "\n",
        "                    # 3. 優先度1 高 - 本物の首と尻尾\n",
        "                    if {'neck', 'tail_base'}.issubset(available_parts):\n",
        "                        neck_x = mouse_data[('x', 'neck')]\n",
        "                        neck_y = mouse_data[('y', 'neck')]\n",
        "                        tail_x = mouse_data[('x', 'tail_base')]\n",
        "                        tail_y = mouse_data[('y', 'tail_base')]\n",
        "\n",
        "                        ratio_neck = 0.568\n",
        "                        est_x_neck = neck_x + (tail_x - neck_x) * ratio_neck\n",
        "                        est_y_neck = neck_y + (tail_y - neck_y) * ratio_neck\n",
        "\n",
        "                        # 優先度1の値を上書き\n",
        "                        final_x = est_x_neck.combine_first(final_x)\n",
        "                        final_y = est_y_neck.combine_first(final_y)\n",
        "\n",
        "                    # 4. 仕上げ: 線形補間\n",
        "                    final_x = final_x.interpolate(method='linear', limit_direction='both')\n",
        "                    final_y = final_y.interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "                    pvid[('x', mid, 'body_center')] = final_x\n",
        "                    pvid[('y', mid, 'body_center')] = final_y\n",
        "\n",
        "                except Exception as e:\n",
        "                    # 個別のマウスで失敗しても他は続ける\n",
        "                    print(f\"Error imputation mouse {mid}: {e}\")\n",
        "                    pass\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in Body Center Imputation: {e}\")\n",
        "            print(f\"Error in processing video {video_id}: {e}\")\n",
        "\n",
        "        # 3. 距離チェック (仕上げ)\n",
        "        if 'clean_distance_outliers' in globals():\n",
        "            pvid = clean_distance_outliers(pvid,\n",
        "                                           pix_per_cm=row.pix_per_cm_approx,\n",
        "                                           threshold_dist_cm=15.0)\n",
        "\n",
        "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
        "        pvid /= row.pix_per_cm_approx\n",
        "\n",
        "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
        "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
        "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
        "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
        "\n",
        "        if traintest == 'train':\n",
        "            try:\n",
        "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
        "            except FileNotFoundError:\n",
        "                continue\n",
        "\n",
        "        # データ生成 (Single)\n",
        "        if generate_single:\n",
        "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
        "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
        "                try:\n",
        "                    mouse_id = int(mouse_id_str[-1])\n",
        "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
        "                    single_mouse = pvid.loc[:, mouse_id]\n",
        "                    assert len(single_mouse) == len(pvid)\n",
        "                    single_mouse_meta = pd.DataFrame({\n",
        "                        'video_id': video_id,\n",
        "                        'agent_id': mouse_id_str,\n",
        "                        'target_id': 'self',\n",
        "                        'video_frame': single_mouse.index\n",
        "                    })\n",
        "                    if traintest == 'train':\n",
        "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
        "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
        "                        for i in range(len(annot_subset)):\n",
        "                            annot_row = annot_subset.iloc[i]\n",
        "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
        "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
        "                    else:\n",
        "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
        "                except KeyError:\n",
        "                    pass\n",
        "\n",
        "        # データ生成 (Pair)\n",
        "        if generate_pair:\n",
        "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
        "            if len(vid_behaviors_subset) > 0:\n",
        "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n",
        "                    agent_str = f\"mouse{agent}\"\n",
        "                    target_str = f\"mouse{target}\"\n",
        "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
        "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
        "                    assert len(mouse_pair) == len(pvid)\n",
        "                    mouse_pair_meta = pd.DataFrame({\n",
        "                        'video_id': video_id,\n",
        "                        'agent_id': agent_str,\n",
        "                        'target_id': target_str,\n",
        "                        'video_frame': mouse_pair.index\n",
        "                    })\n",
        "                    if traintest == 'train':\n",
        "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
        "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
        "                        for i in range(len(annot_subset)):\n",
        "                            annot_row = annot_subset.iloc[i]\n",
        "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
        "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
        "                    else:\n",
        "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b86b7f",
      "metadata": {
        "papermill": {
          "duration": 0.004703,
          "end_time": "2025-11-29T10:09:42.600693",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.595990",
          "status": "completed"
        },
        "tags": [],
        "id": "f1b86b7f"
      },
      "source": [
        "## Transforming coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cbcc400",
      "metadata": {
        "papermill": {
          "duration": 0.025667,
          "end_time": "2025-11-29T10:09:42.631503",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.605836",
          "status": "completed"
        },
        "tags": [],
        "id": "1cbcc400"
      },
      "outputs": [],
      "source": [
        "def safe_rolling(series, window, func, min_periods=None):\n",
        "    if min_periods is None:\n",
        "        min_periods = max(1, window // 4)\n",
        "    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n",
        "\n",
        "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
        "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n",
        "\n",
        "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
        "    if n_frames_at_30fps == 0:\n",
        "        return 0\n",
        "    s = 1 if n_frames_at_30fps > 0 else -1\n",
        "    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n",
        "    return s * mag\n",
        "\n",
        "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
        "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
        "        return float(meta_df['frames_per_second'].iloc[0])\n",
        "    vid = meta_df['video_id'].iloc[0]\n",
        "    return float(fallback_lookup.get(vid, default_fps))\n",
        "\n",
        "def add_curvature_features(X, center_x, center_y, fps):\n",
        "    vel_x = center_x.diff()\n",
        "    vel_y = center_y.diff()\n",
        "    acc_x = vel_x.diff()\n",
        "    acc_y = vel_y.diff()\n",
        "\n",
        "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
        "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
        "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
        "\n",
        "    for w in [25, 50, 75]:\n",
        "        ws = _scale(w, fps)\n",
        "        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
        "\n",
        "    angle = np.arctan2(vel_y, vel_x)\n",
        "    angle_change = np.abs(angle.diff())\n",
        "    w = 30\n",
        "    ws = _scale(w, fps)\n",
        "    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_multiscale_features(X, center_x, center_y, fps):\n",
        "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
        "\n",
        "    scales = [20, 40, 60, 80]\n",
        "    for scale in scales:\n",
        "        ws = _scale(scale, fps)\n",
        "        if len(speed) >= ws:\n",
        "            X[f'sp_m{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).mean()\n",
        "            X[f'sp_s{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).std()\n",
        "\n",
        "    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n",
        "        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_state_features(X, center_x, center_y, fps):\n",
        "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
        "    w_ma = _scale(15, fps)\n",
        "    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n",
        "\n",
        "    try:\n",
        "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
        "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
        "\n",
        "        for window in [20, 40, 60, 80]:\n",
        "            ws = _scale(window, fps)\n",
        "            if len(speed_states) >= ws:\n",
        "                for state in [0, 1]:\n",
        "                    X[f's{state}_{window}'] = (\n",
        "                        (speed_states == state).astype(float)\n",
        "                        .rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
        "                    )\n",
        "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
        "                X[f'trans_{window}'] = state_changes.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_longrange_features(X, center_x, center_y, fps):\n",
        "    for window in [30, 60, 120]:\n",
        "        ws = _scale(window, fps)\n",
        "        if len(center_x) >= ws:\n",
        "            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
        "            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
        "\n",
        "    for span in [30, 60, 120]:\n",
        "        s = _scale(span, fps)\n",
        "        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n",
        "        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
        "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
        "        return X\n",
        "\n",
        "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
        "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
        "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
        "\n",
        "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
        "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
        "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
        "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
        "\n",
        "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
        "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
        "\n",
        "    for window in [30, 60]:\n",
        "        ws = _scale(window, fps)\n",
        "        X[f'A_ld{window}'] = A_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
        "        X[f'B_ld{window}'] = B_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
        "\n",
        "    approach = -rel_dist.diff()\n",
        "    chase = approach * B_lead\n",
        "    w = 30\n",
        "    ws = _scale(w, fps)\n",
        "    X[f'chase_{w}'] = chase.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
        "\n",
        "    for window in [60, 120]:\n",
        "        ws = _scale(window, fps)\n",
        "        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
        "        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
        "        X[f'sp_cor{window}'] = A_sp.rolling(ws, min_periods=max(1, ws // 6)).corr(B_sp)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631e9d57-fbdb-406e-8b88-c84c07a1c877",
      "metadata": {
        "id": "631e9d57-fbdb-406e-8b88-c84c07a1c877"
      },
      "outputs": [],
      "source": [
        "def add_pose_pca(X, coords_df, n_components=3, prefix=\"pose\"):\n",
        "    \"\"\"\n",
        "    マウスの全座標データをPCAにかけて、姿勢を表す主成分特徴量を追加する\n",
        "    coords_df: マウスの座標データフレーム (MultiIndex: bodypart, x/y)\n",
        "    \"\"\"\n",
        "    # 1. 座標データをフラットな数値データとして準備\n",
        "    # (NaNが含まれているとPCAできないので、補間 -> 0埋めで安全に対処)\n",
        "    coords_flat = coords_df.select_dtypes(include=[np.number])\n",
        "    coords_filled = coords_flat.interpolate(method='linear', limit_direction='both').fillna(0)\n",
        "\n",
        "    # 2. 列数が足りているか確認 (部位数が極端に少ない場合はスキップ)\n",
        "    if coords_filled.shape[1] < n_components:\n",
        "        return X\n",
        "\n",
        "    try:\n",
        "        # 3. PCA実行\n",
        "        # \"whiten=True\" で正規化することで、スケールの違いを吸収しやすくなります\n",
        "        pca = PCA(n_components=n_components, whiten=True)\n",
        "        components = pca.fit_transform(coords_filled)\n",
        "\n",
        "        # 4. 特徴量として追加\n",
        "        for i in range(n_components):\n",
        "            X[f'{prefix}_pca{i+1}'] = components[:, i]\n",
        "\n",
        "            # (オプション) 変化量(動きの勢い)も追加するとさらに強力\n",
        "            # X[f'{prefix}_pca{i+1}_vel'] = pd.Series(components[:, i]).diff().fillna(0)\n",
        "\n",
        "    except Exception as e:\n",
        "        # エラーが起きても元のXを返して止まらないようにする\n",
        "        pass\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cbb5be2-f436-4aab-be56-28c7fe9622ff",
      "metadata": {
        "id": "5cbb5be2-f436-4aab-be56-28c7fe9622ff"
      },
      "outputs": [],
      "source": [
        "def add_relative_angle_features(X, mouse_pair, fps):\n",
        "    # 入力チェック (最低限の構造確認)\n",
        "    if X is None: return None\n",
        "    if 'A' not in mouse_pair or 'B' not in mouse_pair: return X\n",
        "\n",
        "    try:\n",
        "        # 必要な部位の座標を取得 (なければNaNのDataFrameが返るようにする)\n",
        "        def get_coords(mouse_df, part):\n",
        "            if part in mouse_df.columns.get_level_values(0):\n",
        "                return mouse_df[part]\n",
        "            else:\n",
        "                # 部位がない場合は全フレームNaNのダミーを返す\n",
        "                return pd.DataFrame(np.nan, index=mouse_df.index, columns=['x', 'y'])\n",
        "\n",
        "        # Aの座標\n",
        "        nose_A = get_coords(mouse_pair['A'], 'nose')\n",
        "        tail_A = get_coords(mouse_pair['A'], 'tail_base')\n",
        "        center_A = get_coords(mouse_pair['A'], 'body_center')\n",
        "\n",
        "        # Bの座標\n",
        "        nose_B = get_coords(mouse_pair['B'], 'nose')\n",
        "        tail_B = get_coords(mouse_pair['B'], 'tail_base')\n",
        "        center_B = get_coords(mouse_pair['B'], 'body_center')\n",
        "\n",
        "        # 1. ベクトル計算\n",
        "        vec_A_x = nose_A['x'] - tail_A['x']\n",
        "        vec_A_y = nose_A['y'] - tail_A['y']\n",
        "        vec_B_x = nose_B['x'] - tail_B['x']\n",
        "        vec_B_y = nose_B['y'] - tail_B['y']\n",
        "        vec_AB_x = center_B['x'] - center_A['x']\n",
        "        vec_AB_y = center_B['y'] - center_A['y']\n",
        "\n",
        "        # 2. 角度計算\n",
        "        theta_A = np.arctan2(vec_A_y, vec_A_x)\n",
        "        theta_B = np.arctan2(vec_B_y, vec_B_x)\n",
        "        theta_AB = np.arctan2(vec_AB_y, vec_AB_x)\n",
        "\n",
        "        # 3. 相対角度\n",
        "        angle_A2B = (theta_AB - theta_A + np.pi) % (2 * np.pi) - np.pi\n",
        "        theta_BA = np.arctan2(-vec_AB_y, -vec_AB_x)\n",
        "        angle_B2A = (theta_BA - theta_B + np.pi) % (2 * np.pi) - np.pi\n",
        "        angle_face = (theta_A - theta_B + np.pi) % (2 * np.pi) - np.pi\n",
        "\n",
        "        # 4. 特徴量追加\n",
        "        # (NaNを含む計算でもPandas/Numpyは処理してNaNを返すのでOK)\n",
        "        X['cos_A2B'] = np.cos(angle_A2B)\n",
        "        X['sin_A2B'] = np.sin(angle_A2B)\n",
        "        X['cos_B2A'] = np.cos(angle_B2A)\n",
        "        X['cos_face'] = np.cos(angle_face)\n",
        "\n",
        "        fov_thresholds = {'30': np.deg2rad(30), '45': np.deg2rad(45)}\n",
        "        temp_features = {}\n",
        "\n",
        "        for deg, rad in fov_thresholds.items():\n",
        "            # NaNとの比較はFalseになるが、念のためfillna(False)等はしないでおく\n",
        "            # (欠損しているなら特徴量もNaNであるべき)\n",
        "            is_watching_A = (np.abs(angle_A2B) < rad).astype(float)\n",
        "            # 元がNaNだった場所は0(False)になってしまうので、マスクしてNaNに戻す\n",
        "            is_watching_A[angle_A2B.isna()] = np.nan\n",
        "\n",
        "            is_watching_B = (np.abs(angle_B2A) < rad).astype(float)\n",
        "            is_watching_B[angle_B2A.isna()] = np.nan\n",
        "\n",
        "            is_mutual = (is_watching_A * is_watching_B)\n",
        "\n",
        "            X[f'watch_{deg}deg'] = is_watching_A\n",
        "            temp_features[f'watch_A_{deg}'] = is_watching_A\n",
        "            temp_features[f'mutual_{deg}'] = is_mutual\n",
        "\n",
        "        for w in [10, 30, 60]:\n",
        "            ws = _scale(w, fps)\n",
        "            X[f'ang_std_{w}'] = pd.Series(angle_A2B).rolling(ws, min_periods=1).std()\n",
        "            X[f'm_cos_A2B_{w}'] = X['cos_A2B'].rolling(ws, min_periods=1).mean()\n",
        "            for deg in fov_thresholds.keys():\n",
        "                X[f'watch_ratio_{deg}deg_{w}'] = temp_features[f'watch_A_{deg}'].rolling(ws, min_periods=1).mean()\n",
        "                X[f'watch_dur_{deg}deg_{w}'] = temp_features[f'watch_A_{deg}'].ewm(span=ws, min_periods=1).mean()\n",
        "                X[f'mutual_ratio_{deg}deg_{w}'] = temp_features[f'mutual_{deg}'].rolling(ws, min_periods=1).mean()\n",
        "\n",
        "    except Exception:\n",
        "        # エラーが起きても、作成できた特徴量だけは残して返す\n",
        "        pass\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bbc3e0-95d6-4c39-a5cb-20463fafaba3",
      "metadata": {
        "id": "b7bbc3e0-95d6-4c39-a5cb-20463fafaba3"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 1. 楕円近似特徴量の計算関数 (安全装置付き)\n",
        "# ==========================================\n",
        "def add_ellipse_features(X, coords_df, fps, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    マウスの全座標データから楕円近似による形状特徴量を計算する。\n",
        "    coords_df: MultiIndex columns (bodypart, x/y) を持つ座標データフレーム\n",
        "    prefix: 列名の接頭辞 (例: \"ag_\", \"tg_\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 座標データ (x, y) だけを取り出す\n",
        "        xs = coords_df.xs('x', level=1, axis=1)\n",
        "        ys = coords_df.xs('y', level=1, axis=1)\n",
        "\n",
        "        # ★★★ 安全装置: 有効な点の数が少なすぎる場合はスキップ ★★★\n",
        "        # 各フレームごとに、NaNでない点の数をカウント\n",
        "        valid_points_count = xs.count(axis=1)\n",
        "\n",
        "        # 3点未満のフレームは計算不能なので除外するためのマスクを作成\n",
        "        # (楕円を決めるには最低3点の分散が必要)\n",
        "        valid_mask = valid_points_count >= 3\n",
        "\n",
        "        if valid_mask.sum() == 0:\n",
        "            return X # 計算できるフレームが一つもない場合は終了\n",
        "\n",
        "        # 計算対象のデータだけ抽出\n",
        "        xs_valid = xs.loc[valid_mask]\n",
        "        ys_valid = ys.loc[valid_mask]\n",
        "\n",
        "        # 部位ごとの分散と共分散を計算\n",
        "        var_x = xs_valid.var(axis=1)\n",
        "        var_y = ys_valid.var(axis=1)\n",
        "\n",
        "        # 共分散: ((x - mean_x) * (y - mean_y)).mean()\n",
        "        mean_x = xs_valid.mean(axis=1)\n",
        "        mean_y = ys_valid.mean(axis=1)\n",
        "        cov_xy = ((xs_valid.subtract(mean_x, axis=0)) * (ys_valid.subtract(mean_y, axis=0))).mean(axis=1)\n",
        "\n",
        "        # 固有値計算 (楕円の長軸・短軸の分散)\n",
        "        term1 = (var_x + var_y) / 2\n",
        "        term2 = np.sqrt((var_x - var_y)**2 + 4 * cov_xy**2) / 2\n",
        "\n",
        "        lambda1 = term1 + term2 # 長軸方向の分散 (大きい方)\n",
        "        lambda2 = term1 - term2 # 短軸方向の分散 (小さい方)\n",
        "\n",
        "        # --- 特徴量作成 (計算結果を元のインデックスに戻す) ---\n",
        "\n",
        "        # 1. 楕円の形状比率 (長軸 / 短軸)\n",
        "        # lambda2 が 0 に近すぎると無限大になるのでクリップ\n",
        "        ratio = np.sqrt(lambda1 / (lambda2.clip(lower=1e-6)))\n",
        "        X.loc[valid_mask, f'{prefix}ellipse_ratio'] = ratio\n",
        "\n",
        "        # 2. 楕円の面積 (簡易版: lambda1 * lambda2)\n",
        "        area = np.sqrt(lambda1 * lambda2)\n",
        "        X.loc[valid_mask, f'{prefix}ellipse_area'] = area\n",
        "\n",
        "        # 3. 楕円の角度 (Orientation) - pi/2 ~ pi/2\n",
        "        angle = 0.5 * np.arctan2(2 * cov_xy, var_x - var_y)\n",
        "        X.loc[valid_mask, f'{prefix}ellipse_angle'] = angle\n",
        "\n",
        "        # --- 統計量を追加 (移動平均など) ---\n",
        "        for w in [10, 30, 60]:\n",
        "            ws = _scale(w, fps)\n",
        "            # 姿勢の変化率\n",
        "            col_ratio = f'{prefix}ellipse_ratio'\n",
        "            if col_ratio in X.columns:\n",
        "                X[f'{prefix}shape_chg_{w}'] = X[col_ratio].diff().abs().rolling(ws, min_periods=1).mean()\n",
        "\n",
        "            # 面積の変化\n",
        "            col_area = f'{prefix}ellipse_area'\n",
        "            if col_area in X.columns:\n",
        "                X[f'{prefix}area_chg_{w}'] = X[col_area].diff().rolling(ws, min_periods=1).mean()\n",
        "\n",
        "    except Exception:\n",
        "        # 計算エラーが起きても元のXを返して止まらない\n",
        "        pass\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_social_proximity_features(X, mouse_pair, fps):\n",
        "    # 重心または鼻を使って距離を計算 (重心優先)\n",
        "    if 'body_center' in mouse_pair['A'].columns.get_level_values(0) and \\\n",
        "       'body_center' in mouse_pair['B'].columns.get_level_values(0):\n",
        "        p1, p2 = mouse_pair['A']['body_center'], mouse_pair['B']['body_center']\n",
        "    elif 'nose' in mouse_pair['A'].columns.get_level_values(0) and \\\n",
        "         'nose' in mouse_pair['B'].columns.get_level_values(0):\n",
        "        p1, p2 = mouse_pair['A']['nose'], mouse_pair['B']['nose']\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "    # 距離計算 (データは既にcm単位になっている前提)\n",
        "    dist = np.sqrt((p1['x'] - p2['x'])**2 + (p1['y'] - p2['y'])**2)\n",
        "\n",
        "    # --- 1. 近接率 (Proximity Density) ---\n",
        "    # 閾値 (cm): 密着(2.5), 近距離(5.0), 中距離(10.0)\n",
        "    thresholds = [2.5, 5.0, 10.0]\n",
        "    windows = [30, 90] # 短期(1秒), 長期(3秒)\n",
        "\n",
        "    for th in thresholds:\n",
        "        # 距離が閾値以下かどうかのフラグ (0 or 1)\n",
        "        is_close = (dist < th).astype(float)\n",
        "\n",
        "        for w in windows:\n",
        "            ws = _scale(w, fps)\n",
        "            # 移動平均をとることで「密度（割合）」になる\n",
        "            X[f'prox_rate_{th}cm_{w}'] = is_close.rolling(ws, min_periods=1).mean()\n",
        "\n",
        "    # --- 2. 連続近接カウンター (Duration) ---\n",
        "    # 5cm以内にいる連続フレーム数をカウント (簡易実装: 指数加重移動平均で代用)\n",
        "    # ずっと近くにいると値が大きくなり続ける\n",
        "    is_close_5cm = (dist < 5.0).astype(float)\n",
        "    # spanを大きくすると、途切れずに継続しているときに値が蓄積される\n",
        "    X['prox_dur_5cm'] = is_close_5cm.ewm(span=_scale(120, fps), min_periods=1).mean()\n",
        "\n",
        "    # --- 3. 距離のヒストグラム的特徴 (分位点) ---\n",
        "    # 過去60フレームにおける距離の「最小・25%・50%・75%」点\n",
        "    ws_long = _scale(60, fps)\n",
        "    roll = dist.rolling(ws_long, min_periods=ws_long//2)\n",
        "    X['dist_p05'] = roll.quantile(0.05) # ほぼ最小値 (異常値除け)\n",
        "    X['dist_p25'] = roll.quantile(0.25) # 第一四分位数\n",
        "    X['dist_p50'] = roll.median()       # 中央値\n",
        "    # 四分位範囲 (IQR): 距離のばらつきの安定した指標\n",
        "    X['dist_iqr'] = X['dist_p50'] - X['dist_p25']\n",
        "\n",
        "    return X\n",
        "\n",
        "def add_movement_features(X, center_x, center_y, fps):\n",
        "    # 1. 速度 (Speed) [cm/s]\n",
        "    # diff() は「1フレーム間の移動距離」なので、fpsを掛けて秒速にする\n",
        "    dist = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
        "    speed = dist * float(fps)\n",
        "\n",
        "    # 2. 加速度 (Acceleration) [cm/s^2]\n",
        "    # 速度の差分 * fps\n",
        "    accel = speed.diff() * float(fps)\n",
        "\n",
        "    # 3. 加加速度 (Jerk) [cm/s^3]\n",
        "    # 加速度の差分 * fps\n",
        "    #jerk = accel.diff() * float(fps)\n",
        "\n",
        "    # --- 特徴量として追加 ---\n",
        "    # そのままの値（瞬間値）\n",
        "    X['speed'] = speed.fillna(0)\n",
        "   # X['accel'] = accel.fillna(0)\n",
        "   # X['jerk']  = jerk.fillna(0)\n",
        "\n",
        "    # 絶対値（大きさ）\n",
        "  #  X['accel_abs'] = accel.abs().fillna(0)\n",
        "  #  X['jerk_abs']  = jerk.abs().fillna(0)\n",
        "\n",
        "    # 移動平均（トレンド）\n",
        "   # for w in [5, 15, 30]: # 短めのウィンドウで急な変化を捉える\n",
        "   #     ws = _scale(w, fps)\n",
        "\n",
        "        # 加速度の平均（勢い）\n",
        "   #     X[f'accel_m{w}'] = X['accel_abs'].rolling(ws, min_periods=1).mean()\n",
        "\n",
        "        # Jerkの平均（動きの荒さ・滑らかさ）\n",
        "        # 値が小さいほど滑らか、大きいほど荒っぽい（攻撃など）\n",
        "    #    X[f'jerk_m{w}'] = X['jerk_abs'].rolling(ws, min_periods=1).mean()\n",
        "\n",
        "   #     # 速度の変化 (長期的な加速・減速トレンド)\n",
        "    #    X[f'speed_change_{w}'] = speed - speed.shift(w)\n",
        "\n",
        "        # 加速度の変化 (Jerkに近いが、より長いスパンでの変化)\n",
        "    #    X[f'accel_change_{w}'] = accel - accel.shift(w)\n",
        "\n",
        "        # 直近の「衝撃」の最大値 (Attackの瞬間に反応しやすい)\n",
        "   # w_short = _scale(10, fps)\n",
        "   # X['max_jerk_10'] = X['jerk_abs'].rolling(w_short, min_periods=1).max()\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f711596c-82f4-49ef-9fd5-229011d110e5",
      "metadata": {
        "id": "f711596c-82f4-49ef-9fd5-229011d110e5"
      },
      "outputs": [],
      "source": [
        "def add_future_features(X, fps):\n",
        "    # 未来を見たい重要な列を指定 (速度、距離、角度など)\n",
        "    # 未来を見たい重要な列 (シングル・ペア共通のスーパーセット)\n",
        "\n",
        "    important_features = [\n",
        "        # 1. 動きの基本 (既存)\n",
        "      #  'speed', 'accel_abs',\n",
        "\n",
        "        # 2. ★追加: 動きの質・方向 (重要！)\n",
        "      #  'jerk_abs',      # 急激な衝撃 (Attack/Escapeの予兆)\n",
        "      #  'vel_forward',   # 前進か後退か (Approach vs Retreat)\n",
        "        'turn_rate_30',  # 旋回 (探索や追跡の開始)\n",
        "\n",
        "        # 3. ★追加: 姿勢・形状\n",
        "        'body_shrink_ratio', # 立ち上がり (Rear)\n",
        "        'ellipse_ratio',     # 体の伸び縮み (Huddle/Chase)\n",
        "\n",
        "        # 4. ★追加: 場所\n",
        "        'dist_to_wall',      # 壁際への移動 (不安行動)\n",
        "\n",
        "        # 5. ★追加: 社会的関係 (ペア用)\n",
        "        'cos_A2B',           # 相手を向いているか (注目)\n",
        "        'prox_rate_5.0cm_30' # 最近近づいていたか (親密度)\n",
        "    ]\n",
        "\n",
        "    # Xに含まれているものだけを対象にする\n",
        "    target_cols = [c for c in X.columns if c in important_features]\n",
        "\n",
        "    # 追加したいウィンドウサイズ\n",
        "    windows = [30, 60]\n",
        "\n",
        "    # データフレームを反転 (未来 -> 過去)\n",
        "    X_reversed = X.iloc[::-1]\n",
        "\n",
        "    for col in target_cols:\n",
        "        for w in windows:\n",
        "            ws = _scale(w, fps)\n",
        "\n",
        "            # 反転した状態で移動平均を計算\n",
        "            # (つまり、現在地点から「未来」に向かっての平均になる)\n",
        "            future_mean = X_reversed[col].rolling(ws, min_periods=1).mean()\n",
        "\n",
        "            # 再反転して元の順序に戻す\n",
        "            future_mean = future_mean.iloc[::-1]\n",
        "\n",
        "            # 特徴量として追加\n",
        "            X[f'fut_m{w}_{col}'] = future_mean\n",
        "\n",
        "            # 簡易的に「未来平均 - 現在値」も有効\n",
        "\n",
        "            X[f'fut_diff_{w}_{col}'] = future_mean - X[col]\n",
        "\n",
        "    return X\n",
        "\n",
        "def calculate_band_power(y, fps, low_freq=5.0, high_freq=10.0):\n",
        "    \"\"\"\n",
        "    指定された周波数帯域のパワーを計算する\n",
        "    \"\"\"\n",
        "    n = len(y)\n",
        "    if n == 0: return 0.0\n",
        "\n",
        "    # 直流成分除去\n",
        "    y = y - np.mean(y)\n",
        "\n",
        "    # FFT実行\n",
        "    fft_val = np.fft.rfft(y)\n",
        "    power = np.abs(fft_val)**2\n",
        "\n",
        "    # 周波数軸を作成\n",
        "    freqs = np.fft.rfftfreq(n, d=1/fps)\n",
        "\n",
        "    # 指定帯域のマスクを作成\n",
        "    mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
        "\n",
        "    # 帯域内のパワー合計を返す\n",
        "    if mask.sum() > 0:\n",
        "        return np.sum(power[mask])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def add_frequency_features(X, fps):\n",
        "    # 対象とする特徴量\n",
        "    targets = []\n",
        "    if 'accel_abs' in X.columns: targets.append('accel_abs') # 動きの激しさ\n",
        "    if 'jerk_abs' in X.columns: targets.append('jerk_abs')   # 動きの滑らかさ\n",
        "    if 'body_shrink_ratio' in X.columns: targets.append('body_shrink_ratio') # 姿勢の震え\n",
        "\n",
        "    if not targets: return X\n",
        "\n",
        "    # ウィンドウサイズ (約1秒〜2秒)\n",
        "    # FFTの周波数分解能はウィンドウサイズで決まるため、ある程度の長さが必要\n",
        "    w = 60 # 約2秒\n",
        "    ws = _scale(w, fps)\n",
        "\n",
        "    # 注目する帯域のリスト (Hz)\n",
        "    # 1-5Hz: 歩行などのゆっくりしたリズム\n",
        "    # 5-10Hz: Groomingなどの細かい震え\n",
        "    # 10Hz+: 非常に速い動き (Attackなど)\n",
        "    bands = [\n",
        "        (1.0, 5.0, 'low'),\n",
        "        (5.0, 10.0, 'mid'),\n",
        "        (10.0, 15.0, 'high')\n",
        "    ]\n",
        "\n",
        "    for col in targets:\n",
        "        # まずNaNを埋める (FFTエラー回避)\n",
        "        # 前方・後方埋め -> 0埋め の順で安全に\n",
        "        series = X[col].fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "        for low, high, name in bands:\n",
        "            # ラムダ関数で fps などの引数を固定して apply に渡す\n",
        "            # raw=True で numpy 配列として渡す (高速化)\n",
        "            X[f'fft_{col}_{name}'] = series.rolling(ws).apply(\n",
        "                lambda y: calculate_band_power(y, fps, low, high),\n",
        "                raw=True\n",
        "            )\n",
        "\n",
        "            # 計算できなかった部分は0埋め\n",
        "            X[f'fft_{col}_{name}'] = X[f'fft_{col}_{name}'].fillna(0)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e5e609",
      "metadata": {
        "papermill": {
          "duration": 0.034168,
          "end_time": "2025-11-29T10:09:42.670485",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.636317",
          "status": "completed"
        },
        "tags": [],
        "id": "90e5e609"
      },
      "outputs": [],
      "source": [
        "def transform_single(single_mouse, body_parts_tracked, fps, video_id=None):\n",
        "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
        "\n",
        "    X = pd.DataFrame({\n",
        "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
        "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
        "        if p1 in available_body_parts and p2 in available_body_parts\n",
        "    })\n",
        "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
        "\n",
        "    # =========================================================\n",
        "    # ★★★ 追加: 指定パーツの距離変化 (Change/Diff) ★★★\n",
        "    # =========================================================\n",
        "\n",
        "    # 対象とするパーツのリスト\n",
        "    target_parts = [\"body_center\", \"ear_left\", \"ear_right\", \"head\", \"nose\", \"tail_base\", \"tail_tip\"]\n",
        "\n",
        "    # 実際にデータに存在するパーツだけに絞る\n",
        "    valid_targets = [p for p in target_parts if p in available_body_parts]\n",
        "\n",
        "    # 対象パーツ間の距離カラムを特定\n",
        "    # カラム名が \"p1+p2\" の形式であることを利用してフィルタリング\n",
        "    target_cols = []\n",
        "    for col in X.columns:\n",
        "        if '+' in col:\n",
        "            p1, p2 = col.split('+')\n",
        "            # 両方のパーツがターゲットリストに含まれている場合のみ対象\n",
        "            if p1 in valid_targets and p2 in valid_targets:\n",
        "                target_cols.append(col)\n",
        "\n",
        "    if len(target_cols) > 0:\n",
        "        lag_frames = 10\n",
        "        lag = _scale(lag_frames, fps)\n",
        "\n",
        "        # 指定した列だけを取り出して差分計算\n",
        "        X_diff = X[target_cols].diff(lag)\n",
        "\n",
        "        # 列名変更 (例: nose+tail_chg10)\n",
        "        X_diff.columns = [f\"{c}_chg{lag_frames}\" for c in X_diff.columns]\n",
        "\n",
        "        # 結合\n",
        "        X = pd.concat([X, X_diff], axis=1)\n",
        "\n",
        "        # (オプション) 対象パーツだけの伸縮合計\n",
        "        X[f'major_parts_expansion_{lag_frames}'] = X_diff.sum(axis=1)\n",
        "    # =========================================================\n",
        "    # =========================================================\n",
        "\n",
        "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
        "        lag = _scale(10, fps)\n",
        "        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
        "        speeds = pd.DataFrame({\n",
        "            'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
        "            'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
        "            'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
        "            'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
        "        })\n",
        "        X = pd.concat([X, speeds], axis=1)\n",
        "\n",
        "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
        "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
        "\n",
        "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
        "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
        "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
        "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
        "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
        "\n",
        "    if 'body_center' in available_body_parts:\n",
        "        cx = single_mouse['body_center']['x']\n",
        "        cy = single_mouse['body_center']['y']\n",
        "\n",
        "        for w in [5, 15, 30, 60, 90, 120]:\n",
        "            ws = _scale(w, fps)\n",
        "            roll = dict(min_periods=1, center=True)\n",
        "            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
        "            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
        "            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
        "            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
        "            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
        "            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
        "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
        "                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n",
        "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n",
        "                                   cy.diff().rolling(ws, min_periods=1).var())\n",
        "\n",
        "        X = add_curvature_features(X, cx, cy, fps)\n",
        "        X = add_multiscale_features(X, cx, cy, fps)\n",
        "        X = add_state_features(X, cx, cy, fps)\n",
        "        X = add_longrange_features(X, cx, cy, fps)\n",
        "\n",
        "      #  X = add_movement_features(X, cx, cy, fps)\n",
        "\n",
        "    # =================================================\n",
        "    # ★★★ ここを追加！ (Rear特化の特徴量) ★★★\n",
        "    # =================================================\n",
        "    if 'neck' in available_body_parts and 'tail_base' in available_body_parts:\n",
        "        # 首と尻尾の距離\n",
        "        d_neck_tail = np.sqrt((single_mouse['neck']['x'] - single_mouse['tail_base']['x'])**2 +\n",
        "                              (single_mouse['neck']['y'] - single_mouse['tail_base']['y'])**2)\n",
        "\n",
        "        # 通常時の体長（移動平均の最大値）との比率\n",
        "        # (立ち上がると短くなる -> 値が小さくなる)\n",
        "        w_long = _scale(60, fps)\n",
        "        X['body_shrink_ratio'] = d_neck_tail / (d_neck_tail.rolling(w_long, min_periods=1).max() + 1e-6)\n",
        "\n",
        "        # 長さの変化量\n",
        "        X['body_len_change'] = d_neck_tail.diff()\n",
        "\n",
        "    if 'ear_left' in available_body_parts and 'ear_right' in available_body_parts:\n",
        "        # 両耳の距離\n",
        "        d_ears = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
        "                         (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
        "\n",
        "        # 普段より耳が離れているか？ (カメラに近づいたか)\n",
        "        w_long = _scale(60, fps)\n",
        "        X['head_size_ratio'] = d_ears / (d_ears.rolling(w_long, min_periods=1).mean() + 1e-6)\n",
        "\n",
        "    # =================================================\n",
        "\n",
        "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
        "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
        "                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
        "        for lag in [10, 20, 40]:\n",
        "            l = _scale(lag, fps)\n",
        "            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
        "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
        "\n",
        "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
        "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
        "                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
        "        for off in [-30, -20, -10, 10, 20, 30]:\n",
        "            o = _scale_signed(off, fps)\n",
        "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
        "        w = _scale(30, fps)\n",
        "        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n",
        "                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
        "    # 単独の姿勢PCA\n",
        "    X = add_pose_pca(X, single_mouse, n_components=3, prefix=\"ag\") # agent\n",
        "    X = add_ellipse_features(X, single_mouse, fps, prefix=\"\")\n",
        "    if video_id is not None and 'add_arena_features' in globals():\n",
        "        try:\n",
        "            X = add_arena_features(X, single_mouse, video_id, fps)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Arena features failed for {video_id}: {e}\")\n",
        "            pass\n",
        "\n",
        "    # ★★★ 追加: 未来の特徴量 ★★★\n",
        "    X = add_future_features(X, fps)\n",
        "    # ★★★ 追加: 周波数特徴量 ★★★\n",
        "    # (計算に時間がかかるので、まずは single だけに入れる等の調整もアリ)\n",
        " #   X = add_frequency_features(X, fps)\n",
        "\n",
        "    return X.astype(np.float32, copy=False)\n",
        "def transform_pair(mouse_pair, body_parts_tracked, fps):\n",
        "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
        "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
        "\n",
        "    X = pd.DataFrame({\n",
        "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
        "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
        "        if p1 in avail_A and p2 in avail_B\n",
        "    })\n",
        "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
        "\n",
        "    # =========================================================\n",
        "    # ★★★ 追加: 指定パーツの距離変化 (Change/Diff) - Pair版 ★★★\n",
        "    # =========================================================\n",
        "\n",
        "    # 対象とするパーツのリスト\n",
        "    target_parts = [\"body_center\", \"ear_left\", \"ear_right\", \"head\", \"nose\", \"tail_base\", \"tail_tip\"]\n",
        "\n",
        "    # 実際にデータに存在するパーツだけに絞る (AとBそれぞれ)\n",
        "    valid_targets_A = [p for p in target_parts if p in avail_A]\n",
        "    valid_targets_B = [p for p in target_parts if p in avail_B]\n",
        "\n",
        "    # 対象パーツ間の距離カラムを特定\n",
        "    target_cols = []\n",
        "\n",
        "    # 全列を走査するより、有効なパーツの組み合わせから列名を作って探す方が速い\n",
        "    for p1 in valid_targets_A:\n",
        "        for p2 in valid_targets_B:\n",
        "            col_name = f\"12+{p1}+{p2}\"\n",
        "            if col_name in X.columns:\n",
        "                target_cols.append(col_name)\n",
        "\n",
        "    if len(target_cols) > 0:\n",
        "        lag_frames = 10\n",
        "        lag = _scale(lag_frames, fps)\n",
        "\n",
        "        # 指定した列だけを取り出して差分計算\n",
        "        X_diff = X[target_cols].diff(lag)\n",
        "\n",
        "        # 列名変更 (例: 12+nose+tail_chg10)\n",
        "        X_diff.columns = [f\"{c}_chg{lag_frames}\" for c in X_diff.columns]\n",
        "\n",
        "        # 結合\n",
        "        X = pd.concat([X, X_diff], axis=1)\n",
        "\n",
        "        # (オプション) 全体の接近・離反の合計\n",
        "        # ペア間の距離変化の合計なので、マイナスなら「全体的に近づいている」、プラスなら「離れている」\n",
        "        X[f'major_parts_approach_{lag_frames}'] = X_diff.sum(axis=1)\n",
        "    # =========================================================\n",
        "    # =========================================================\n",
        "\n",
        "    if ('A', 'ear_right') in mouse_pair.columns and ('B', 'ear_right') in mouse_pair.columns:\n",
        "        lag = _scale(10, fps)\n",
        "        shA = mouse_pair['A']['ear_right'].shift(lag)\n",
        "        shB = mouse_pair['B']['ear_right'].shift(lag)\n",
        "        speeds = pd.DataFrame({\n",
        "            'sp_A': np.square(mouse_pair['A']['ear_right'] - shA).sum(axis=1, skipna=False),\n",
        "            'sp_AB': np.square(mouse_pair['A']['ear_right'] - shB).sum(axis=1, skipna=False),\n",
        "            'sp_B': np.square(mouse_pair['B']['ear_right'] - shB).sum(axis=1, skipna=False),\n",
        "        })\n",
        "        X = pd.concat([X, speeds], axis=1)\n",
        "\n",
        "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
        "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
        "\n",
        "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
        "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
        "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
        "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
        "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
        "\n",
        "    #if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
        "   #     cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
        "  #      lag = _scale(10, fps)\n",
        "   #     shA_n = mouse_pair['A']['nose'].shift(lag)\n",
        "  #      shB_n = mouse_pair['B']['nose'].shift(lag)\n",
        "  #      past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
        " #       X['appr'] = cur - past\n",
        "\n",
        "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
        "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
        "                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
        "    #    X['v_cls'] = (cd < 5.0).astype(float)\n",
        "     #   X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
        "     #   X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
        "     #   X['far']   = (cd >= 30.0).astype(float)\n",
        "\n",
        "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
        "        dist = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
        "        # 2. ★改良: 直線距離 (cm)\n",
        "        cd_full = np.sqrt(dist)\n",
        "        # 3. ★改良: 接近速度 (マイナス=接近, プラス=離反)\n",
        "        appr_vel = dist.diff()\n",
        "        j = _scale(30, fps)\n",
        "        X['int_con'] = cd_full.rolling(j, min_periods=1, center=True).std() / \\\n",
        "                    (cd_full.rolling(j, min_periods=1, center=True).mean() + 1e-6)\n",
        "\n",
        "        for w in [5, 15, 30, 45, 60, 75, 90, 120, 150]:\n",
        "            ws = _scale(w, fps)\n",
        "            roll = dict(min_periods=1, center=True)\n",
        "            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
        "            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
        "            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
        "            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
        "\n",
        "            d_var = cd_full.rolling(ws, **roll).var()\n",
        "            X[f'int{w}'] = 1 / (1 + d_var)\n",
        "            # --- ★改良: 変動係数 (距離の安定性) ---\n",
        "            # (距離が近くて、かつ変動が少ない = Grooming/Huddle)\n",
        "            X[f'd_cv{w}'] = X[f'd_s{w}'] / (X[f'd_m{w}'] + 1.0)\n",
        "            # --- ★改良: 接近の勢い ---\n",
        "            # 平均接近速度 (Attackの予兆)\n",
        "            X[f'appr_m{w}'] = appr_vel.rolling(ws, **roll).mean()\n",
        "            # 最大接近速度 (一瞬の飛びかかり)\n",
        "            X[f'appr_min{w}'] = appr_vel.rolling(ws, **roll).min()\n",
        "\n",
        "            Axd = mouse_pair['A']['body_center']['x'].diff()\n",
        "            Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
        "            Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
        "            Byd = mouse_pair['B']['body_center']['y'].diff()\n",
        "            coord = Axd * Bxd + Ayd * Byd\n",
        "            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
        "            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
        "\n",
        "    if 'nose' in avail_A and 'nose' in avail_B:\n",
        "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
        "                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
        "        for lag in [10, 20, 40]:\n",
        "            l = _scale(lag, fps)\n",
        "            X[f'nn_lg{lag}']  = nn.shift(l)\n",
        "            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n",
        "            is_cl = (nn < 10.0).astype(float)\n",
        "            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n",
        "\n",
        "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
        "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
        "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
        "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
        "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
        "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
        "\n",
        "  #      for off in [-30, -20, -10, 0, 10, 20, 30]:\n",
        "  #          o = _scale_signed(off, fps)\n",
        "  #          X[f'va_{off}'] = val.shift(-o)\n",
        "\n",
        "   #     w = _scale(30, fps)\n",
        "   #     X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
        "  #                     (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
        "\n",
        "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
        "\n",
        "    # マウスA (Agent) の姿勢\n",
        "    X = add_pose_pca(X, mouse_pair['A'], n_components=3, prefix=\"ag\")\n",
        "    # マウスB (Target) の姿勢\n",
        "    X = add_pose_pca(X, mouse_pair['B'], n_components=3, prefix=\"tg\")\n",
        "    X = add_relative_angle_features(X, mouse_pair, fps)\n",
        "\n",
        "    # A (Agent) の姿勢: 接頭辞 \"A_\"\n",
        "    X = add_ellipse_features(X, mouse_pair['A'], fps, prefix=\"A_\")\n",
        "\n",
        "    # B (Target) の姿勢: 接頭辞 \"B_\"\n",
        "    X = add_ellipse_features(X, mouse_pair['B'], fps, prefix=\"B_\")\n",
        "\n",
        "    # 相対的な姿勢の違い (もし両方計算できていれば)\n",
        "    if 'A_ellipse_ratio' in X.columns and 'B_ellipse_ratio' in X.columns:\n",
        "        X['ellipse_ratio_diff'] = X['A_ellipse_ratio'] - X['B_ellipse_ratio']\n",
        "\n",
        "    X = add_social_proximity_features(X, mouse_pair, fps)\n",
        "    # ★★★ 追加: 未来の特徴量 ★★★\n",
        "    X = add_future_features(X, fps)\n",
        "    # ★★★ 追加: 周波数特徴量 ★★★\n",
        "    # (計算に時間がかかるので、まずは single だけに入れる等の調整もアリ)\n",
        "#    X = add_frequency_features(X, fps)\n",
        "    return X.astype(np.float32, copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32383bdd-f7fe-4cb7-b71b-fc6007ea4ea8",
      "metadata": {
        "id": "32383bdd-f7fe-4cb7-b71b-fc6007ea4ea8"
      },
      "outputs": [],
      "source": [
        "def add_arena_features(X, single_mouse, video_id, fps):\n",
        "    # body_center がなければスキップ\n",
        "    if 'body_center' not in single_mouse.columns.get_level_values(0):\n",
        "        return X\n",
        "\n",
        "    # video_metadata から環境情報を取得\n",
        "    try:\n",
        "        info = video_metadata.loc[video_id]\n",
        "        W_pix = float(info['video_width_pix'])\n",
        "        H_pix = float(info['video_height_pix'])\n",
        "        W_arena = float(info['arena_width_cm'])\n",
        "        H_arena = float(info['arena_height_cm'])\n",
        "        ppc = float(info['pix_per_cm'])\n",
        "    except KeyError:\n",
        "        return X\n",
        "\n",
        "    # 座標 (既にcm単位になっている前提)\n",
        "    cx = single_mouse['body_center']['x']\n",
        "    cy = single_mouse['body_center']['y']\n",
        "\n",
        "    # --- 座標系の補正 (画面中央を原点 (0,0) に見立てる) ---\n",
        "    # ビデオ全体の幅・高さ (cm)\n",
        "    W_video_cm = W_pix / ppc\n",
        "    H_video_cm = H_pix / ppc\n",
        "\n",
        "    # 中心からのオフセット\n",
        "    center_x_offset = W_video_cm / 2\n",
        "    center_y_offset = H_video_cm / 2\n",
        "\n",
        "    # アリーナの半径\n",
        "    r_w = W_arena / 2\n",
        "    r_h = H_arena / 2\n",
        "\n",
        "    # 1. アリーナ中心からの距離\n",
        "    X['dist_to_center'] = np.sqrt((cx - center_x_offset)**2 + (cy - center_y_offset)**2)\n",
        "\n",
        "    # 2. 壁までの距離\n",
        "    # (アリーナ半径 - 中心からの距離)\n",
        "    dist_x = (cx - center_x_offset).abs()\n",
        "    dist_y = (cy - center_y_offset).abs()\n",
        "\n",
        "    dist_wall_x = r_w - dist_x\n",
        "    dist_wall_y = r_h - dist_y\n",
        "\n",
        "    # 最も近い壁までの距離\n",
        "    X['dist_to_wall'] = np.minimum(dist_wall_x, dist_wall_y)\n",
        "\n",
        "    # 3. ゾーン判定\n",
        "    X['is_wall_zone'] = (X['dist_to_wall'] < 5.0).astype(float)\n",
        "    X['is_center_zone'] = (X['dist_to_center'] < 10.0).astype(float)\n",
        "\n",
        "    # --- 滞在時間の割合 ---\n",
        "    for window in [30, 90, 300]:\n",
        "        ws = _scale(window, fps)\n",
        "        X[f'wall_ratio_{window}'] = X['is_wall_zone'].rolling(ws, min_periods=1).mean()\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89327a41-9563-4973-9eab-c00301ad2abd",
      "metadata": {
        "id": "89327a41-9563-4973-9eab-c00301ad2abd"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# ★ メタデータ注入を行う専用関数\n",
        "# ==========================================\n",
        "def add_metadata_features(X, meta, video_metadata):\n",
        "    \"\"\"\n",
        "    特徴量DataFrame(X)に、メタデータ(lab_id, tracking_method, strain, sex)を注入する\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. 現在のビデオIDを取得\n",
        "        vid = meta['video_id'].iloc[0]\n",
        "\n",
        "        # 2. video_metadata からそのビデオの情報を取得\n",
        "        vid_info = video_metadata.loc[vid]\n",
        "\n",
        "        # 3. 共通情報の追加 (lab_id, tracking_method)\n",
        "        # float32にキャストしてメモリ節約＆型統一\n",
        "        X['lab_id'] = vid_info['lab_id'].astype(np.float32)\n",
        "        X['tracking_method'] = vid_info['tracking_method'].astype(np.float32)\n",
        "\n",
        "        # 4. Agent/Target に応じた情報の追加\n",
        "        # マッピング辞書の準備\n",
        "        strain_map = {f'mouse{i}': vid_info[f'mouse{i}_strain'] for i in range(1, 5)}\n",
        "        sex_map = {f'mouse{i}': vid_info[f'mouse{i}_sex'] for i in range(1, 5)}\n",
        "\n",
        "        # map関数を使って代入\n",
        "        X['agent_strain'] = meta['agent_id'].map(strain_map).values.astype(np.float32)\n",
        "        X['agent_sex'] = meta['agent_id'].map(sex_map).values.astype(np.float32)\n",
        "\n",
        "        # Pairの場合のみ target_id があるので追加\n",
        "        if 'target_id' in meta.columns and (meta['target_id'] != 'self').any():\n",
        "            # target_id がある行だけ計算（Singleの場合はエラーにならないようにチェック）\n",
        "            X['target_strain'] = meta['target_id'].map(strain_map).values.astype(np.float32)\n",
        "            X['target_sex'] = meta['target_id'].map(sex_map).values.astype(np.float32)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Metadata injection failed for video {vid}: {e}\")\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73099c3",
      "metadata": {
        "papermill": {
          "duration": 0.004809,
          "end_time": "2025-11-29T10:09:42.680250",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.675441",
          "status": "completed"
        },
        "tags": [],
        "id": "c73099c3"
      },
      "source": [
        "# Training, validation and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f8dbb1",
      "metadata": {
        "_kg_hide-input": false,
        "papermill": {
          "duration": 0.015228,
          "end_time": "2025-11-29T10:09:42.700200",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.684972",
          "status": "completed"
        },
        "tags": [],
        "id": "44f8dbb1"
      },
      "outputs": [],
      "source": [
        "def robustify(submission, dataset, traintest, traintest_directory=None, min_duration_frames=8, gap_fill_frames=8):\n",
        "    if traintest_directory is None:\n",
        "        traintest_directory = f\"CFG.input_dir/{traintest}_tracking\"\n",
        "\n",
        "    if len(submission) == 0: return submission\n",
        "\n",
        "    # 1. 基本的なクリーニング\n",
        "    submission = submission[submission.start_frame < submission.stop_frame]\n",
        "\n",
        "    # 2. Bout処理 (隙間埋め & 短い行動削除)\n",
        "    #min_duration_frames = 10\n",
        "    #gap_fill_frames = 10\n",
        "    processed_list = []\n",
        "\n",
        "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id', 'action']):\n",
        "        group = group.sort_values('start_frame')\n",
        "        group['prev_stop'] = group['stop_frame'].shift(1)\n",
        "        group['gap'] = group['start_frame'] - group['prev_stop']\n",
        "        group['bout_id'] = (group['gap'] > gap_fill_frames).fillna(True).cumsum()\n",
        "\n",
        "        merged_bouts = group.groupby('bout_id').agg({\n",
        "            'video_id': 'first', 'agent_id': 'first', 'target_id': 'first', 'action': 'first',\n",
        "            'start_frame': 'min', 'stop_frame': 'max'\n",
        "        }).reset_index(drop=True)\n",
        "\n",
        "        merged_bouts['duration'] = merged_bouts['stop_frame'] - merged_bouts['start_frame']\n",
        "        merged_bouts = merged_bouts[merged_bouts['duration'] >= min_duration_frames]\n",
        "\n",
        "        if len(merged_bouts) > 0:\n",
        "            processed_list.append(merged_bouts[['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']])\n",
        "\n",
        "    if len(processed_list) > 0:\n",
        "        submission = pd.concat(processed_list).sort_values(['video_id', 'start_frame'])\n",
        "    else:\n",
        "        return pd.DataFrame(columns=submission.columns) # 空ならここで終了\n",
        "\n",
        "    # =========================================================\n",
        "    # ★★★ 最終防衛ライン: 重複部分だけをトリミングして残す ★★★\n",
        "    # =========================================================\n",
        "\n",
        "    final_rows = []\n",
        "\n",
        "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
        "        # 開始時間順にソート\n",
        "        group = group.sort_values(['start_frame', 'stop_frame'])\n",
        "\n",
        "        # 確定した予測区間を保持するリスト [(start, stop), ...]\n",
        "        occupied_intervals = []\n",
        "\n",
        "        for idx, row in group.iterrows():\n",
        "            start, stop = row['start_frame'], row['stop_frame']\n",
        "            original_duration = stop - start\n",
        "\n",
        "            # 既存の区間と被っているかチェック\n",
        "            is_overlapped = False\n",
        "\n",
        "            # 単純化のため、既存区間の「最大終了時刻」を管理して比較\n",
        "            # (ソート済みなので、直前の区間と比較するだけで大抵はOKだが、念のため全走査に近い形にする)\n",
        "            # しかし計算量削減のため、ここでは「一番後ろの区間」との比較をメインにする\n",
        "\n",
        "            if not occupied_intervals:\n",
        "                occupied_intervals.append((start, stop))\n",
        "                final_rows.append(row)\n",
        "                continue\n",
        "\n",
        "            # 直前の採用区間を取得\n",
        "            last_start, last_stop = occupied_intervals[-1]\n",
        "\n",
        "            if start < last_stop:\n",
        "                # 被っている！\n",
        "                # 新しい開始時間を「前の終了時間」まで後ろにずらす\n",
        "                new_start = last_stop\n",
        "\n",
        "                if new_start < stop:\n",
        "                    # まだ区間が残っているなら採用\n",
        "                    # ただし、短くなりすぎていないかチェック (Bout制約)\n",
        "                    if (stop - new_start) >= min_duration_frames:\n",
        "                        row['start_frame'] = new_start\n",
        "                        occupied_intervals.append((new_start, stop))\n",
        "                        final_rows.append(row)\n",
        "            else:\n",
        "                # 被っていない（離れている）ならそのまま採用\n",
        "                occupied_intervals.append((start, stop))\n",
        "                final_rows.append(row)\n",
        "\n",
        "    if len(final_rows) > 0:\n",
        "        submission = pd.DataFrame(final_rows)\n",
        "    else:\n",
        "        submission = pd.DataFrame(columns=submission.columns)\n",
        "    # =========================================================\n",
        "\n",
        "    # 3. 穴埋め処理 (Filling missing videos)\n",
        "    s_list = []\n",
        "    for idx, row in dataset.iterrows():\n",
        "        lab_id = row['lab_id']\n",
        "        if traintest == 'train' and lab_id.startswith(('MABe22', 'CalMS21', 'CRIM13')): continue\n",
        "\n",
        "        video_id = row['video_id']\n",
        "        if len(submission) > 0 and (submission.video_id == video_id).any(): continue\n",
        "        if type(row.behaviors_labeled) != str: continue\n",
        "\n",
        "        print(f\"Video {video_id} has no predictions. Filling.\")\n",
        "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
        "        try:\n",
        "            vid = pd.read_parquet(path)\n",
        "            vid_behaviors = json.loads(row['behaviors_labeled'])\n",
        "            vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
        "            vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
        "            vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
        "            start_frame = vid.video_frame.min()\n",
        "            stop_frame = vid.video_frame.max() + 1\n",
        "            for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
        "                batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
        "                for i, (_, action_row) in enumerate(actions.iterrows()):\n",
        "                    batch_start = start_frame + i * batch_length\n",
        "                    batch_stop = min(batch_start + batch_length, stop_frame)\n",
        "                    s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
        "        except: pass\n",
        "\n",
        "    if len(s_list) > 0:\n",
        "        submission = pd.concat([\n",
        "            submission,\n",
        "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
        "        ])\n",
        "        # print(\"ERROR: Filled empty videos\")\n",
        "\n",
        "    submission = submission.reset_index(drop=True)\n",
        "    return submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b525f30a",
      "metadata": {
        "papermill": {
          "duration": 0.012723,
          "end_time": "2025-11-29T10:09:42.717751",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.705028",
          "status": "completed"
        },
        "tags": [],
        "id": "b525f30a"
      },
      "outputs": [],
      "source": [
        "def predict_multiclass(pred, meta, thresholds):\n",
        "    ama = np.argmax(pred.values, axis=1)\n",
        "    max_proba = pred.max(axis=1).values\n",
        "\n",
        "    threshold_array = np.array([thresholds.get(col, 0.27) for col in pred.columns])\n",
        "    action_thresholds = threshold_array[ama]\n",
        "\n",
        "    ama = np.where(max_proba >= action_thresholds, ama, -1)\n",
        "    ama = pd.Series(ama, index=meta.video_frame)\n",
        "\n",
        "    changes_mask = (ama != ama.shift(1)).values\n",
        "    ama_changes = ama[changes_mask]\n",
        "    meta_changes = meta[changes_mask]\n",
        "\n",
        "    mask = ama_changes.values >= 0\n",
        "    mask[-1] = False\n",
        "\n",
        "    submission_part = pd.DataFrame({\n",
        "        'video_id': meta_changes['video_id'][mask].values,\n",
        "        'agent_id': meta_changes['agent_id'][mask].values,\n",
        "        'target_id': meta_changes['target_id'][mask].values,\n",
        "        'action': pred.columns[ama_changes[mask].values],\n",
        "        'start_frame': ama_changes.index[mask],\n",
        "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
        "    })\n",
        "\n",
        "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
        "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
        "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
        "    for i in range(len(submission_part)):\n",
        "        video_id = submission_part.video_id.iloc[i]\n",
        "        agent_id = submission_part.agent_id.iloc[i]\n",
        "        target_id = submission_part.target_id.iloc[i]\n",
        "        if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
        "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
        "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
        "\n",
        "    return submission_part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bdcf97",
      "metadata": {
        "papermill": {
          "duration": 0.010167,
          "end_time": "2025-11-29T10:09:42.732704",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.722537",
          "status": "completed"
        },
        "tags": [],
        "id": "b9bdcf97"
      },
      "outputs": [],
      "source": [
        "def tune_threshold(oof_action, y_action):\n",
        "    def objective(trial):\n",
        "        threshold = trial.suggest_float(\"threshold\", 0, 1, step=0.01)\n",
        "        return f1_score(y_action, (oof_action >= threshold), zero_division=0)\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=1000, n_jobs=-1)\n",
        "    return study.best_params[\"threshold\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b683c5c",
      "metadata": {
        "papermill": {
          "duration": 0.009889,
          "end_time": "2025-11-29T10:09:42.784154",
          "exception": false,
          "start_time": "2025-11-29T10:09:42.774265",
          "status": "completed"
        },
        "tags": [],
        "id": "6b683c5c"
      },
      "outputs": [],
      "source": [
        "if CFG.mode == \"validate\":\n",
        "    thresholds = {\n",
        "        \"single\": {},\n",
        "        \"pair\": {}\n",
        "    }\n",
        "else:\n",
        "    thresholds = joblib.load(f\"{CFG.model_path}/{CFG.model_name}/thresholds.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e270d957-fa84-40a2-b427-f193b3cb42d4",
      "metadata": {
        "id": "e270d957-fa84-40a2-b427-f193b3cb42d4"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "#from catboost import CatBoostClassifier\n",
        "\n",
        "def cross_validate_classifier(X_pl, label, meta, body_parts_tracked_str, section, model_type=\"xgboost\"):\n",
        "    # model_type: \"xgboost\", \"lightgbm\", \"catboost\" のいずれか\n",
        "\n",
        "    oof = pd.DataFrame(index=meta.video_frame)\n",
        "    f1_list = []\n",
        "    submission_list = []\n",
        "    thresholds = {}\n",
        "    gc.collect()\n",
        "\n",
        "    for action in label.columns:\n",
        "        # ラベル準備\n",
        "        action_mask = ~ label[action].isna().values\n",
        "        y_action = label[action][action_mask].values.astype(int)\n",
        "        X_action = X_pl[action_mask]\n",
        "        groups_action = meta.video_id[action_mask].values\n",
        "\n",
        "        if len(np.unique(groups_action)) < CFG.n_splits: continue\n",
        "\n",
        "        # アクションが存在する場合のみ学習\n",
        "        if not (y_action == 0).all():\n",
        "            print(f\"Start training {model_type} for {action}...\")\n",
        "\n",
        "            oof_preds = np.zeros(len(y_action), dtype=np.float32)\n",
        "            best_f1_score = -1.0\n",
        "            best_fold_idx = -1\n",
        "            best_threshold = 0.5\n",
        "\n",
        "            cv = StratifiedGroupKFold(n_splits=CFG.n_splits)\n",
        "\n",
        "            for fold, (train_idx, val_idx) in enumerate(cv.split(X_action, y_action, groups=groups_action)):\n",
        "                X_train_fold = X_action.iloc[train_idx]\n",
        "                y_train_fold = y_action[train_idx]\n",
        "                X_val_fold = X_action.iloc[val_idx]\n",
        "\n",
        "                # scale_pos_weight 計算\n",
        "                num_neg = (y_train_fold == 0).sum()\n",
        "                num_pos = (y_train_fold == 1).sum()\n",
        "                pos_weight = np.sqrt(num_neg / num_pos) if num_pos > 0 else 1.0\n",
        "                print(f\"  Fold {fold}: Neg={num_neg}, Pos={num_pos}, Weight={pos_weight:.2f}\")\n",
        "                # ==========================================\n",
        "                # ★ モデル定義の切り替えスイッチ\n",
        "                # ==========================================\n",
        "                if model_type == \"xgboost\":\n",
        "                    model = XGBClassifier(\n",
        "                        # --- 固定設定 ---\n",
        "                        verbosity=0,\n",
        "                        random_state=42,\n",
        "                        device='cuda',\n",
        "                        tree_method='hist',\n",
        "                        n_estimators=3000, # 学習率0.13ならこれで十分足ります\n",
        "\n",
        "                        # --- ★今回見つけたベストパラメータ ---\n",
        "                        max_depth=6,\n",
        "                        learning_rate=0.132,       # 0.1318... を丸めました\n",
        "                        min_child_weight=10,\n",
        "                        subsample=0.728,\n",
        "                        colsample_bytree=0.771,\n",
        "                        reg_alpha=1.58,\n",
        "                        reg_lambda=3.44,\n",
        "\n",
        "                        # --- 変動設定 ---\n",
        "                        scale_pos_weight=pos_weight,\n",
        "                        early_stopping_rounds=50,\n",
        "                    )\n",
        "\n",
        "                elif model_type == \"lightgbm\":\n",
        "                    model = lgb.LGBMClassifier(\n",
        "                        random_state=42, device='gpu', # GPUがない環境なら 'cpu'\n",
        "                        n_estimators=3000, learning_rate=0.05, num_leaves=31,\n",
        "                        scale_pos_weight=pos_weight,\n",
        "                        verbose=-1\n",
        "                    )\n",
        "\n",
        "                elif model_type == \"catboost\":\n",
        "                    model = CatBoostClassifier(\n",
        "                        random_state=42, task_type=\"GPU\", # GPUがない環境なら \"CPU\"\n",
        "                        iterations=3000, learning_rate=0.05, depth=6,\n",
        "                        scale_pos_weight=pos_weight,\n",
        "                        verbose=0, allow_writing_files=False\n",
        "                    )\n",
        "                # ==========================================\n",
        "\n",
        "                # 学習 (XGB, LGBM, Cat 共通のAPIでいけます)\n",
        "                # CatBoost向けにeval_setの渡し方が少し違いますが、sklearn APIならこれでも動くことが多いです\n",
        "                # 厳密にやるなら分岐しますが、まずは簡易版で\n",
        "                if model_type == \"catboost\":\n",
        "                    model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_action[val_idx]), early_stopping_rounds=50, verbose=False)\n",
        "                elif model_type == \"xgboost\":\n",
        "                    # XGBはコンストラクタでearly_stopping指定済みならfitでは不要、バージョンの違い吸収のためシンプルに\n",
        "                     model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_action[val_idx])], verbose=False)\n",
        "                else: # LightGBM\n",
        "                    # LGBMは callbacksが必要な場合があるが、最新版はこれでいけることが多い\n",
        "                    model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_action[val_idx])],\n",
        "                              callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)])\n",
        "\n",
        "                # 保存ディレクトリ\n",
        "                save_dir = f\"{CFG.model_name}/{section}/{action}\"\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "                # 特徴量保存 (Fold0のみ)\n",
        "                if fold == 0:\n",
        "                    with open(f\"{save_dir}/features.json\", \"w\") as f:\n",
        "                        json.dump(list(X_train_fold.columns), f)\n",
        "\n",
        "                # ★ 保存ファイル名をモデルごとに変える！ (これがアンサンブルの鍵)\n",
        "                # 例: xgboost_fold_0.pkl, lightgbm_fold_0.pkl\n",
        "                file_name = f\"{model_type}_fold_{fold}.pkl\"\n",
        "                joblib.dump(model, f\"{save_dir}/{file_name}\")\n",
        "\n",
        "                # 推論 & スコア更新\n",
        "                val_preds = model.predict_proba(X_val_fold)[:, 1]\n",
        "                oof_preds[val_idx] = val_preds\n",
        "\n",
        "                # ベストスコア更新処理...\n",
        "                current_y_true = y_action[val_idx]\n",
        "                current_th = tune_threshold(val_preds, current_y_true)\n",
        "                current_f1 = f1_score(current_y_true, (val_preds >= current_th), zero_division=0)\n",
        "                print(f\"    -> Fold {fold} Score: {current_f1:.4f} (th={current_th:.2f})\")\n",
        "                if current_f1 > best_f1_score:\n",
        "                    best_f1_score = current_f1\n",
        "                    best_fold_idx = fold\n",
        "                    best_threshold = current_th\n",
        "                    print(f\"    [{model_type}] Fold {fold} New Best! F1: {current_f1:.4f}\")\n",
        "\n",
        "                del X_train_fold, y_train_fold, X_val_fold, model\n",
        "                gc.collect()\n",
        "\n",
        "            # --- Fold Loop End ---\n",
        "            # 閾値の最適化\n",
        "            threshold = tune_threshold(oof_preds, y_action)\n",
        "            thresholds[action] = threshold\n",
        "\n",
        "            f1 = f1_score(y_action, (oof_preds >= threshold), zero_division=0)\n",
        "            f1_list.append((body_parts_tracked_str, action, f1))\n",
        "\n",
        "            # 保存処理\n",
        "            # ★ 修正1: OOFなども上書きされないように名前に model_type をつける\n",
        "            joblib.dump(oof_preds, f\"{save_dir}/oof_pred_probs_{model_type}.pkl\")\n",
        "            joblib.dump(threshold, f\"{save_dir}/threshold_{model_type}.pkl\")\n",
        "\n",
        "            print(f\"\\tF1: {f1:.4f} ({threshold:.2f}) Section: {section} Action: {action}\")\n",
        "\n",
        "            # ==========================================\n",
        "            # ✅ ベストモデル情報の保存 (ループの外で行う！)\n",
        "                # ==========================================\n",
        "            print(f\"\\n🏆 Best Fold: {best_fold_idx} with F1: {best_f1_score:.4f}\")\n",
        "\n",
        "            best_info = {\n",
        "                \"best_fold\": int(best_fold_idx), # intに変換しないとJSONエラーになることがある\n",
        "                \"best_f1\": float(best_f1_score),\n",
        "                \"best_threshold\": float(best_threshold)\n",
        "            }\n",
        "\n",
        "                # save_dir はループ内で定義されているので、再度パスを指定するかループ外で定義が必要\n",
        "                # (ここでは念のため再定義)\n",
        "            save_dir = f\"{CFG.model_name}/{section}/{action}\"\n",
        "\n",
        "            with open(f\"{save_dir}/best_model_info.json\", \"w\") as f:\n",
        "                json.dump(best_info, f)\n",
        "\n",
        "                # ベストモデルをコピー\n",
        "            if best_fold_idx != -1:\n",
        "                import shutil\n",
        "                # ★ 修正2: \"xgb_\" 固定ではなく model_type 変数を使う\n",
        "                src_model = f\"{save_dir}/{model_type}_fold_{best_fold_idx}.pkl\"\n",
        "                dst_model = f\"{save_dir}/{model_type}_best.pkl\"\n",
        "                if os.path.exists(src_model):\n",
        "                    shutil.copy(src_model, dst_model)\n",
        "                    print(f\"  -> Copied best model to: {dst_model}\")\n",
        "                else:\n",
        "                    print(f\"  Warning: Source model {src_model} not found.\")\n",
        "                # ==========================================\n",
        "\n",
        "        else:\n",
        "            oof_preds = np.zeros(len(y_action))\n",
        "            print(f\"\\tF1: 0.0000 (0.00) Section: {section} Action: {action}\")\n",
        "\n",
        "        # 全体の配列に戻す\n",
        "        oof_column = np.zeros(len(label))\n",
        "        oof_column[action_mask] = oof_preds\n",
        "        oof[action] = oof_column\n",
        "\n",
        "        # ループごとのクリーンアップ\n",
        "        del action_mask, X_action, y_action, groups_action\n",
        "        if 'oof_preds' in locals(): del oof_preds\n",
        "        gc.collect()\n",
        "\n",
        "    submission_part = predict_multiclass(oof, meta, thresholds)\n",
        "    submission_list.append(submission_part)\n",
        "\n",
        "    return submission_list, f1_list, thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a299202-26d0-4b7d-82e7-f7d33235d70b",
      "metadata": {
        "id": "9a299202-26d0-4b7d-82e7-f7d33235d70b"
      },
      "outputs": [],
      "source": [
        "# 1. 必要なカラムをリストアップ\n",
        "meta_cols = [\n",
        "    'video_id', 'lab_id', 'tracking_method',\n",
        "    'video_width_pix', 'video_height_pix',\n",
        "    'arena_width_cm', 'arena_height_cm', 'pix_per_cm_approx'\n",
        "] + [f'mouse{i}_{attr}' for i in range(1, 5) for attr in ['strain', 'sex']]\n",
        "\n",
        "# 2. Train/Testから読み込んで結合\n",
        "raw_meta = pd.concat([\n",
        "    pd.read_csv(CFG.train_path, usecols=meta_cols),\n",
        "    pd.read_csv(CFG.test_path, usecols=meta_cols)\n",
        "], axis=0).drop_duplicates('video_id').set_index('video_id')\n",
        "\n",
        "# 3. video_metadata の作成\n",
        "video_metadata = pd.DataFrame(index=raw_meta.index)\n",
        "\n",
        "# 数値データはそのままコピー (ここが追加点！)\n",
        "video_metadata['video_width_pix'] = raw_meta['video_width_pix']\n",
        "video_metadata['video_height_pix'] = raw_meta['video_height_pix']\n",
        "video_metadata['arena_width_cm']  = raw_meta['arena_width_cm']\n",
        "video_metadata['arena_height_cm'] = raw_meta['arena_height_cm']\n",
        "video_metadata['pix_per_cm']      = raw_meta['pix_per_cm_approx']\n",
        "\n",
        "# カテゴリカルデータはエンコード\n",
        "le_lab = LabelEncoder()\n",
        "video_metadata['lab_id'] = le_lab.fit_transform(raw_meta['lab_id'].fillna('unknown'))\n",
        "\n",
        "le_track = LabelEncoder()\n",
        "video_metadata['tracking_method'] = le_track.fit_transform(raw_meta['tracking_method'].fillna('unknown'))\n",
        "\n",
        "# Strain & Sex\n",
        "le_strain = LabelEncoder()\n",
        "all_strains = pd.concat([raw_meta[f'mouse{i}_strain'] for i in range(1, 5)]).fillna('unknown').astype(str).unique()\n",
        "le_strain.fit(all_strains)\n",
        "\n",
        "le_sex = LabelEncoder()\n",
        "all_sexes = pd.concat([raw_meta[f'mouse{i}_sex'] for i in range(1, 5)]).fillna('unknown').astype(str).unique()\n",
        "le_sex.fit(all_sexes)\n",
        "\n",
        "for i in range(1, 5):\n",
        "    video_metadata[f'mouse{i}_strain'] = le_strain.transform(raw_meta[f'mouse{i}_strain'].fillna('unknown').astype(str))\n",
        "    video_metadata[f'mouse{i}_sex'] = le_sex.transform(raw_meta[f'mouse{i}_sex'].fillna('unknown').astype(str))\n",
        "\n",
        "print(\"Metadata prepared (with Arena Info)!\")\n",
        "display(video_metadata.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4440a5-7a0f-4bc0-a4ca-f69e6904b6f3",
      "metadata": {
        "id": "2c4440a5-7a0f-4bc0-a4ca-f69e6904b6f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 保存先設定\n",
        "CHECKPOINT_DIR = \"./checkpoints\"\n",
        "# 一時ファイル保存用フォルダ\n",
        "TEMP_DIR = \"./temp_features\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Checkpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"Temp files: {TEMP_DIR}\")\n",
        "\n",
        "f1_list = []\n",
        "submission_list = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# =========================================================\n",
        "# ★ AdaptableSnail かつ 25fps の動画を除外する処理\n",
        "# (ループに入る前に1回だけ実行する！)\n",
        "# =========================================================\n",
        "if 'train' in locals():\n",
        "    print(f\"Original train size: {len(train)}\")\n",
        "\n",
        "    # 条件: lab_id が 'AdaptableSnail' かつ frames_per_second が 25.0\n",
        "    # (train にこの列がある前提です)\n",
        "    drop_mask = (train['lab_id'] == 'AdaptableSnail') & (train['frames_per_second'] == 25.0)\n",
        "\n",
        "    # 除外される動画数を確認\n",
        "    dropped_cnt = train[drop_mask]['video_id'].nunique()\n",
        "    if dropped_cnt > 0:\n",
        "        print(f\"🚫 Dropping {dropped_cnt} videos (AdaptableSnail @ 25fps)...\")\n",
        "        # フィルタリング実行\n",
        "        train = train[~drop_mask].reset_index(drop=True)\n",
        "        print(f\"Filtered train size: {len(train)}\")\n",
        "    else:\n",
        "        print(\"No videos to drop.\")\n",
        "# =========================================================\n",
        "\n",
        "for section in range(1, len(body_parts_tracked_list)):\n",
        "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
        "    checkpoint_path = f\"{CHECKPOINT_DIR}/section_{section}.pkl\"\n",
        "\n",
        "    # === A. チェックポイント読み込み ===\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Found checkpoint for Section {section}. Loading...\")\n",
        "        try:\n",
        "            temp_submission_list, temp_f1_list, temp_thresholds = joblib.load(checkpoint_path)\n",
        "            f1_list.extend(temp_f1_list)\n",
        "            submission_list.extend(temp_submission_list)\n",
        "\n",
        "            # 閾値復元 (validate時)\n",
        "            if CFG.mode == 'validate':\n",
        "                if f\"{section}\" not in thresholds[\"single\"].keys():\n",
        "                    thresholds[\"single\"][f\"{section}\"] = {}\n",
        "                if f\"{section}\" not in thresholds[\"pair\"].keys():\n",
        "                    thresholds[\"pair\"][f\"{section}\"] = {}\n",
        "                for k, v in temp_thresholds.items():\n",
        "                    if k in thresholds[\"single\"][f\"{section}\"]:\n",
        "                        thresholds[\"single\"][f\"{section}\"][k] = v\n",
        "                    elif k in thresholds[\"pair\"][f\"{section}\"]:\n",
        "                        thresholds[\"pair\"][f\"{section}\"][k] = v\n",
        "\n",
        "            print(f\"-> Section {section} loaded! Skipping processing.\\n\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load checkpoint: {e}. Recalculating...\")\n",
        "\n",
        "    # === B. 計算実行 ===\n",
        "    try:\n",
        "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
        "        if 'body_center' not in body_parts_tracked:\n",
        "            body_parts_tracked.append('body_center')\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        elapsed_str = str(timedelta(seconds=int(elapsed)))\n",
        "        print(f\"[{elapsed_str}] {section}/{len(body_parts_tracked_list)-1} Processing videos with: {body_parts_tracked}\\n\")\n",
        "\n",
        "        if len(body_parts_tracked) > 5:\n",
        "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
        "\n",
        "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
        "\n",
        "        _fps_lookup = (\n",
        "            train_subset[['video_id', 'frames_per_second']]\n",
        "            .drop_duplicates('video_id')\n",
        "            .set_index('video_id')['frames_per_second']\n",
        "            .to_dict()\n",
        "        )\n",
        "\n",
        "        # リストに貯めずに、一時ファイルパスを記録するリストにする\n",
        "        #single_temp_files = []\n",
        "        #pair_temp_files = []\n",
        "\n",
        "        single_X_list = []  # 特徴量 (X) 用\n",
        "        pair_X_list = []    # 特徴量 (X) 用\n",
        "\n",
        "        single_label_list = []\n",
        "        single_meta_list = []\n",
        "        pair_label_list = []\n",
        "        pair_meta_list = []\n",
        "\n",
        "        #file_counter = 0\n",
        "\n",
        "        # ★ 修正ポイント: ループ内で即座に特徴量計算して保存\n",
        "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train', traintest_directory=CFG.train_tracking_path):\n",
        "\n",
        "            fps_i = _fps_from_meta(meta, _fps_lookup, default_fps=30.0)\n",
        "            vid = meta['video_id'].iloc[0]\n",
        "            if switch == 'single':\n",
        "                # 1. すぐに特徴量変換 (float32でOK)\n",
        "                X_i = transform_single(data, body_parts_tracked, fps_i, video_id=vid).astype(np.float32)\n",
        "\n",
        "                # 2. ★ メタデータ注入 (関数呼び出しに変更！) ★\n",
        "                X_i = add_metadata_features(X_i, meta, video_metadata)\n",
        "\n",
        "                # 3. ★修正: リストに直接追加 (ファイル保存しない)\n",
        "                single_X_list.append(X_i)\n",
        "                single_label_list.append(label)\n",
        "                single_meta_list.append(meta)\n",
        "\n",
        "                # 3. すぐにParquetに保存\n",
        "                #temp_path = f\"{TEMP_DIR}/single_{section}_{file_counter}.parquet\"\n",
        "                #X_i.columns = X_i.columns.astype(str)\n",
        "                #X_i.to_parquet(temp_path, index=False)\n",
        "\n",
        "                #single_temp_files.append(temp_path)\n",
        "                #single_label_list.append(label)\n",
        "                #single_meta_list.append(meta)\n",
        "\n",
        "                #del X_i # メモリから消す！\n",
        "\n",
        "            else:\n",
        "                # 1. すぐに特徴量変換\n",
        "                X_i = transform_pair(data, body_parts_tracked, fps_i).astype(np.float32)\n",
        "\n",
        "                # 2. ★ メタデータ注入 (関数呼び出しに変更！) ★\n",
        "                X_i = add_metadata_features(X_i, meta, video_metadata)\n",
        "\n",
        "                # 3. ★修正: リストに直接追加\n",
        "                pair_X_list.append(X_i)\n",
        "                pair_label_list.append(label)\n",
        "                pair_meta_list.append(meta)\n",
        "\n",
        "                # 3. すぐにParquetに保存\n",
        "                #temp_path = f\"{TEMP_DIR}/pair_{section}_{file_counter}.parquet\"\n",
        "                #X_i.columns = X_i.columns.astype(str)\n",
        "                #X_i.to_parquet(temp_path, index=False)\n",
        "\n",
        "                #pair_temp_files.append(temp_path)\n",
        "                #pair_label_list.append(label)\n",
        "                #pair_meta_list.append(meta)\n",
        "\n",
        "                #del X_i # メモリから消す！\n",
        "\n",
        "            del data, meta, label\n",
        "            #file_counter += 1\n",
        "\n",
        "            # 定期的にGCを実行\n",
        "            #if file_counter % 10 == 0:\n",
        "            #    gc.collect()\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        current_section_submission = []\n",
        "        current_section_f1 = []\n",
        "        current_section_thresholds = {}\n",
        "\n",
        "        # --- Single Mouse Processing ---\n",
        "        if len(single_X_list) > 0:\n",
        "            print(f\"Loading {len(single_X_list)} single mouse feature files...\")\n",
        "\n",
        "            # Polarsを使って全Parquetファイルを一気に読み込む (高速 & 省メモリ)\n",
        "            # scan_parquet は遅延読み込みなのでメモリを食わない\n",
        "     #       try:\n",
        "       #         X_pl = pl.read_parquet(single_temp_files) # filesリストを渡せば結合してくれる\n",
        "     #       except:\n",
        "   #             # バージョンによってはリスト渡しができない場合があるのでconcatする\n",
        "    #            X_pl = pl.concat([pl.read_parquet(f) for f in single_temp_files])\n",
        "            #try:\n",
        "            #    X_pl = pl.concat(\n",
        "            #        [pl.scan_parquet(f) for f in single_temp_files],\n",
        "           #         how=\"diagonal\"\n",
        "             #   ).collect()\n",
        "          #  except Exception as e:\n",
        "           #     print(f\"Lazy load failed ({e}), trying eager load...\")\n",
        "                # 万が一Lazyでコケた場合のフォールバック (1つずつ読み込む)\n",
        "            #    X_pl = pl.concat(\n",
        "           #         [pl.read_parquet(f) for f in single_temp_files],\n",
        "            #        how=\"diagonal\"\n",
        "            #    )\n",
        "\n",
        "            # ★修正: Pandasで一括読み込み＆結合\n",
        "            # axis=0 で縦に結合、ignore_index=True でインデックスを振り直す\n",
        "            #X_pd_list = [pd.read_parquet(f) for f in single_temp_files]\n",
        "            #X_pl = pd.concat(X_pd_list, axis=0, ignore_index=True)\n",
        "\n",
        "            # ★修正: メモリ上のリストを一気に結合\n",
        "            X_pl = pd.concat(single_X_list, axis=0, ignore_index=True)\n",
        "            # ラベルとメタデータはPandasで結合\n",
        "            single_mouse_label = pd.concat(single_label_list, axis=0, ignore_index=True)\n",
        "            single_mouse_meta = pd.concat(single_meta_list, axis=0, ignore_index=True)\n",
        "\n",
        "            # 完了したのでリスト削除\n",
        "            del single_label_list, single_meta_list, single_X_list\n",
        "            gc.collect()\n",
        "\n",
        "            # inf対策 (Polars)\n",
        "            #float_cols = X_pl.select(pl.col([pl.Float32, pl.Float64])).columns\n",
        "            #X_pl = X_pl.with_columns([\n",
        "            #    pl.when(pl.col(c).is_infinite()).then(None).otherwise(pl.col(c)).alias(c)\n",
        "            #    for c in float_cols\n",
        "            #])\n",
        "            # ... (X_te 生成直後) ...\n",
        "\n",
        "            # --- 特徴量の内訳カウント ---\n",
        "            print(f\"\\n[Feature Count Report] Total: {len(X_pl.columns)} columns\")\n",
        "\n",
        "            # カテゴリごとのキーワード\n",
        "            categories = {\n",
        "                'Distance': ['+', 'dist'],\n",
        "                'Speed/Accel': ['speed', 'accel', 'jerk', 'sp_', 'disp', 'act'],\n",
        "                'Angle/Pose': ['ang', 'ori', 'curv', 'turn', 'ellipse'],\n",
        "                'Arena/Zone': ['wall', 'center', 'zone'],\n",
        "                'Future': ['fut_'],\n",
        "                'Frequency': ['fft_'],\n",
        "                'Metadata': ['lab_id', 'strain', 'sex', 'method'],\n",
        "                'Interaction': ['prox', 'watch', 'mutual', '12+']\n",
        "            }\n",
        "\n",
        "            for cat, keywords in categories.items():\n",
        "                count = sum(1 for c in X_pl.columns if any(k in c for k in keywords))\n",
        "                if count > 0:\n",
        "                    print(f\"  - {cat}: {count}\")\n",
        "\n",
        "            # -----------------------------\n",
        "            if CFG.mode == 'validate':\n",
        "                temp_sub, temp_f1, temp_th = cross_validate_classifier(X_pl, single_mouse_label, single_mouse_meta, body_parts_tracked_str, section, model_type=\"xgboost\")\n",
        "\n",
        "                if f\"{section}\" not in thresholds[\"single\"].keys():\n",
        "                    thresholds[\"single\"][f\"{section}\"] = {}\n",
        "                for k, v in temp_th.items():\n",
        "                    thresholds[\"single\"][f\"{section}\"][k] = v\n",
        "\n",
        "                f1_list.extend(temp_f1)\n",
        "                submission_list.extend(temp_sub)\n",
        "\n",
        "                current_section_f1.extend(temp_f1)\n",
        "                current_section_submission.extend(temp_sub)\n",
        "                current_section_thresholds.update(temp_th)\n",
        "\n",
        "                del temp_sub, temp_f1, temp_th, X_pl\n",
        "                gc.collect()\n",
        "            else:\n",
        "         #       temp_sub = submit(body_parts_tracked_str, 'single', section, thresholds[\"single\"][f\"{section}\"])\n",
        "       #         submission_list.extend(temp_sub)\n",
        "         #       current_section_submission.extend(temp_sub)\n",
        "         #       del temp_sub, X_pl\n",
        "                gc.collect()\n",
        "\n",
        "        # --- Mouse Pair Processing ---\n",
        "\n",
        "        if len(pair_X_list) > 0:\n",
        "            print(f\"Loading and Downsampling {len(pair_X_list)} mouse pair files...\")\n",
        "\n",
        "            # リストに全データを貯めず、間引いたものだけを入れる\n",
        "            #X_pl_list = []\n",
        "            #y_list = []\n",
        "            #meta_list = []\n",
        "\n",
        "            # 1つずつ読み込んで、その場で間引く！\n",
        "            #for i, (feat_file, label_df, meta_df) in enumerate(zip(pair_temp_files, pair_label_list, pair_meta_list)):\n",
        "\n",
        "                # 1. 特徴量を読み込む\n",
        "             #   df = pl.read_parquet(feat_file)\n",
        "\n",
        "                # 2. 保持する行を決める（validateモードのみ）\n",
        "            #    if CFG.mode == 'validate':\n",
        "                    # ラベルが1つでもある行（ポジティブ）を探す\n",
        "                    # (label_df は Pandas なので numpy にして計算)\n",
        "           #         has_action = label_df.values.sum(axis=1) > 0\n",
        "\n",
        "           #         pos_idx = np.where(has_action)[0]\n",
        "             #       neg_idx = np.where(~has_action)[0]\n",
        "\n",
        "                    # ネガティブデータ（行動なし）を「10%」に間引く！(ここが軽量化のキモ)\n",
        "                    # メモリが厳しければ 0.05 (5%) にしてもOK\n",
        "             #       if len(neg_idx) > 0:\n",
        "            #            np.random.seed(42 + i) # 再現性確保\n",
        "            #            keep_neg_count = int(len(neg_idx) * 0.1)\n",
        "            #            neg_idx_sampled = np.random.choice(neg_idx, size=keep_neg_count, replace=False)\n",
        "           #         else:\n",
        "           #             neg_idx_sampled = []\n",
        "\n",
        "          #          # 結合してソート\n",
        "            #        keep_idx = np.concatenate([pos_idx, neg_idx_sampled])\n",
        "          #          keep_idx.sort()\n",
        "\n",
        "                    # 3. データをフィルタリング（小さくする）\n",
        "           #         df = df[keep_idx]\n",
        "            #        label_df = label_df.iloc[keep_idx]\n",
        "            #        meta_df = meta_df.iloc[keep_idx]\n",
        "\n",
        "                # リストに追加\n",
        "          #      X_pl_list.append(df)\n",
        "          #      y_list.append(label_df)\n",
        "          #      meta_list.append(meta_df)\n",
        "\n",
        "                # こまめにGC\n",
        "            #    if i % 100 == 0: gc.collect()\n",
        "            # =================================================\n",
        "            # ★ ログ出力: diagonal結合で何個nullが増えるか計算\n",
        "            # =================================================\n",
        "            # 1. 全データフレームに含まれるユニークな列名を集める\n",
        "           # all_columns = set()\n",
        "           # original_total_cells = 0\n",
        "           # total_rows = 0\n",
        "\n",
        "           # for df in X_pl_list:\n",
        "          #      all_columns.update(df.columns)\n",
        "          #      original_total_cells += (df.height * df.width)\n",
        "          #      total_rows += df.height\n",
        "          #\n",
        "           # final_col_count = len(all_columns)\n",
        "           # final_total_cells = total_rows * final_col_count\n",
        "          #\n",
        "         #   filled_count = final_total_cells - original_total_cells\n",
        "         #   fill_ratio = (filled_count / final_total_cells) * 100 if final_total_cells > 0 else 0\n",
        "\n",
        "        #    print(f\"  [Diagonal Concat info]\")\n",
        "        #    print(f\"  - Unified columns: {final_col_count}\")\n",
        "            #print(f\"  - Cells filled with null: {filled_count:,} ({fill_ratio:.2f}%)\")\n",
        "         #   # =================================================\n",
        "\n",
        "            # 結合（ダウンサンプリング済みなので軽い！）\n",
        "            #X_pl = pl.concat(X_pl_list, how=\"diagonal\")\n",
        "            #mouse_pair_label = pd.concat(y_list, axis=0, ignore_index=True)\n",
        "            #mouse_pair_meta = pd.concat(meta_list, axis=0, ignore_index=True)\n",
        "\n",
        "            # お掃除\n",
        "            #del pair_label_list, pair_meta_list, X_pl_list, y_list, meta_list\n",
        "            #gc.collect()\n",
        "\n",
        "            # inf対策\n",
        "            #float_cols = X_pl.select(pl.col([pl.Float32, pl.Float64])).columns\n",
        "            #X_pl = X_pl.with_columns([\n",
        "            #    pl.when(pl.col(c).is_infinite()).then(None).otherwise(pl.col(c)).alias(c)\n",
        "            #    for c in float_cols\n",
        "            #])\n",
        "            # ... (X_te 生成直後) ...\n",
        "            # ★修正: Pandasで一括読み込み＆結合\n",
        "            #X_pd_list = [pd.read_parquet(f) for f in pair_temp_files]\n",
        "            #X_pl = pd.concat(X_pd_list, axis=0, ignore_index=True)\n",
        "\n",
        "            # ★修正: メモリ上のリストを一気に結合\n",
        "            X_pl = pd.concat(pair_X_list, axis=0, ignore_index=True)\n",
        "\n",
        "            mouse_pair_label = pd.concat(pair_label_list, axis=0, ignore_index=True)\n",
        "            mouse_pair_meta = pd.concat(pair_meta_list, axis=0, ignore_index=True)\n",
        "\n",
        "            del pair_label_list, pair_meta_list, pair_X_list\n",
        "            gc.collect()\n",
        "            # --- 特徴量の内訳カウント ---\n",
        "            print(f\"\\n[Feature Count Report] Total: {len(X_pl.columns)} columns\")\n",
        "\n",
        "            # カテゴリごとのキーワード\n",
        "            categories = {\n",
        "                'Distance': ['+', 'dist'],\n",
        "                'Speed/Accel': ['speed', 'accel', 'jerk', 'sp_', 'disp', 'act'],\n",
        "                'Angle/Pose': ['ang', 'ori', 'curv', 'turn', 'ellipse'],\n",
        "                'Arena/Zone': ['wall', 'center', 'zone'],\n",
        "                'Future': ['fut_'],\n",
        "                'Frequency': ['fft_'],\n",
        "                'Metadata': ['lab_id', 'strain', 'sex', 'method'],\n",
        "                'Interaction': ['prox', 'watch', 'mutual', '12+']\n",
        "            }\n",
        "\n",
        "            for cat, keywords in categories.items():\n",
        "                count = sum(1 for c in X_pl.columns if any(k in c for k in keywords))\n",
        "                if count > 0:\n",
        "                    print(f\"  - {cat}: {count}\")\n",
        "\n",
        "            # -----------------------------\n",
        "            if CFG.mode == 'validate':\n",
        "                # 間引いたデータを渡すので、関数内でのダウンサンプリングは不要だが、\n",
        "                # そのまま渡しても問題ない（念には念を）\n",
        "                temp_sub, temp_f1, temp_th = cross_validate_classifier(X_pl, mouse_pair_label, mouse_pair_meta, body_parts_tracked_str, section)\n",
        "\n",
        "                if f\"{section}\" not in thresholds[\"pair\"].keys():\n",
        "                    thresholds[\"pair\"][f\"{section}\"] = {}\n",
        "                for k, v in temp_th.items():\n",
        "                    thresholds[\"pair\"][f\"{section}\"][k] = v\n",
        "\n",
        "                f1_list.extend(temp_f1)\n",
        "                submission_list.extend(temp_sub)\n",
        "\n",
        "                current_section_f1.extend(temp_f1)\n",
        "                current_section_submission.extend(temp_sub)\n",
        "                current_section_thresholds.update(temp_th)\n",
        "\n",
        "                del temp_sub, temp_f1, temp_th, X_pl\n",
        "                gc.collect()\n",
        "            else:\n",
        "                # submitモードは全量データを使う（間引かない）\n",
        "                # ※注意: submitモードでここを通る場合、メモリが足りなくなる可能性があります\n",
        "          #      temp_sub = submit(body_parts_tracked_str, 'pair', section, thresholds[\"pair\"][f\"{section}\"])\n",
        "         #       submission_list.extend(temp_sub)\n",
        "          #      current_section_submission.extend(temp_sub)\n",
        "       #         del temp_sub, X_pl\n",
        "                gc.collect()\n",
        "\n",
        "        # === 保存 ===\n",
        "        print(f\"Saving checkpoint for Section {section}...\")\n",
        "        joblib.dump(\n",
        "            (current_section_submission, current_section_f1, current_section_thresholds),\n",
        "            checkpoint_path\n",
        "        )\n",
        "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "        # 一時ファイルの掃除（ディスク容量確保のため）\n",
        "        #for f in single_temp_files + pair_temp_files:\n",
        "         #   if os.path.exists(f): os.remove(f)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\tError in Section {section}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb01437-625a-4a2a-89fd-dd36812c747c",
      "metadata": {
        "id": "feb01437-625a-4a2a-89fd-dd36812c747c"
      },
      "outputs": [],
      "source": [
        "print(f\"Submission list items: {len(submission_list)}\")\n",
        "print(f\"F1 list items: {len(f1_list)}\")\n",
        "\n",
        "if len(submission_list) > 0:\n",
        "    print(\"Sample submission type:\", type(submission_list[0])) # pandas.core.frame.DataFrame ならOK\n",
        "else:\n",
        "    print(\"⚠️ Warning: submission_list is empty!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4528970",
      "metadata": {
        "papermill": {
          "duration": 27.74836,
          "end_time": "2025-11-29T16:43:06.037506",
          "exception": false,
          "start_time": "2025-11-29T16:42:38.289146",
          "status": "completed"
        },
        "tags": [],
        "id": "a4528970"
      },
      "outputs": [],
      "source": [
        "if CFG.mode == 'validate':\n",
        "    submission = pd.concat(submission_list)\n",
        "    submission_robust = robustify(submission, train, 'train')\n",
        "    print(f\"Competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
        "\n",
        "    f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
        "    print(f\"Mean F1:            {f1_df['binary F1 score'].mean():.4f}\")\n",
        "\n",
        "    joblib.dump(thresholds, f\"{CFG.model_name}/thresholds.pkl\")\n",
        "    joblib.dump(f1_df, f\"{CFG.model_name}/scores.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 13874099,
          "isSourceIdPinned": false,
          "sourceId": 59156,
          "sourceType": "competition"
        },
        {
          "datasetId": 8619229,
          "sourceId": 13752019,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 23617.554213,
      "end_time": "2025-11-29T16:43:07.215645",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-29T10:09:29.661432",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
